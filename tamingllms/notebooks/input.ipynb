{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(input)=\n",
    "# Managing Input Data\n",
    "```{epigraph}\n",
    "One home run is much better than two doubles.\n",
    "\n",
    "-- Steve Jobs\n",
    "```\n",
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "When building applications with language models, developers often default to complex architectures involving retrieval systems, chunking strategies, and sophisticated pipelines. However, these approaches add unnecessary complexity when simpler solutions exist. This is where long-context language models (LCLMs) {cite}`lee2024longcontextlanguagemodelssubsume` come in. LCLMs are a new class of models that can process massive amounts of text - up to millions of tokens - in a single forward pass. This capability means they can directly ingest and reason about entire documents or datasets without requiring external tools or complex preprocessing steps. The implications are significant: developers can build more maintainable systems by simply feeding raw text to the model rather than orchestrating complicated retrieval and chunking pipelines. Recent benchmarks have shown that this straightforward approach can match or exceed the performance of more complex systems like RAG, despite never being explicitly trained for such tasks. Before implementing sophisticated architectures, developers should first evaluate whether an LCLM's native capabilities might offer a simpler path to their goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Documents\n",
    "\n",
    "When discussing document processing with LLMs, there's often a focus on sophisticated algorithms from chunking to contextual inferencing to RAGs. However, this misses the core challenge in production systems, which is 80% about cleaning and normalizing the input, and 20% about actually algorithmic inferencing.\n",
    "\n",
    "Building robust data ingestion and preprocessing pipelines is essential for any LLM application. This section explores powerful tools and frameworks like MarkItDown, Docling, and LangChain that streamline document processing. These tools provide unified interfaces for converting diverse document formats into standardized representations that LLMs can effectively process. By abstracting away format-specific complexities, they allow developers to focus on core application logic rather than parsing implementation details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarkItDown\n",
    "\n",
    "MarkItDown is a Python package and CLI too developed by the Microsoft AutoGen team for converting various file formats to Markdown. It supports a wide range of formats including PDF, PowerPoint, Word, Excel, images (with OCR and EXIF metadata), audio (with transcription), HTML, and other text-based formats. The tool is particularly useful for document indexing and text analysis tasks.\n",
    "\n",
    "Key features:\n",
    "- Simple command-line and Python API interfaces\n",
    "- Support for multiple file formats\n",
    "- Optional LLM integration for enhanced image descriptions\n",
    "- Batch processing capabilities\n",
    "- Docker support for containerized usage\n",
    "\n",
    "Sample usage:\n",
    "```python\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "md = MarkItDown()\n",
    "result = md.convert(\"test.xlsx\")\n",
    "print(result.text_content)\n",
    "```\n",
    "\n",
    "### Docling\n",
    "\n",
    "Docling is a Python package developed by IBM Research for parsing and converting documents into various formats. It provides advanced document understanding capabilities with a focus on maintaining document structure and formatting.\n",
    "\n",
    "Key features:\n",
    "- Support for multiple document formats (PDF, DOCX, PPTX, XLSX, Images, HTML, etc.)\n",
    "- Advanced PDF parsing including layout analysis and table extraction\n",
    "- Unified document representation format\n",
    "- Integration with LlamaIndex and LangChain\n",
    "- OCR support for scanned documents\n",
    "- Simple CLI interface\n",
    "\n",
    "Sample usage:\n",
    "```python\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(\"document.pdf\")\n",
    "print(result.document.export_to_markdown())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frameworks-Based Parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: Structured Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common use case where document parsing matters is to extract structured data from documents, particularly in the presence of complex formatting and layout. In this case study, we will extract the economic forecasts from Merrill Lynch's CIO Capital Market Outlook released on December 16, 2024 {cite:p}`merrill2024`.  {numref}`forecast` shows page 7 of the mentioned document, which contains several economic variables. \n",
    "\n",
    "\n",
    "```{figure} ../data/input/forecast.png\n",
    "---\n",
    "name: forecast\n",
    "alt: Forecast\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "Forecast\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on the page containing the economic forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_FILE_PATH = \"../data/input/forecast.pdf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will use MarkItDown to extract the text content from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "md = MarkItDown()\n",
    "result_md = md.convert(FORECAST_FILE_PATH).text_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will do the same with Docling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "converter = DocumentConverter()\n",
    "forecast_result_docling = converter.convert(source).document.export_to_markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How similar are the two results? We can use use Levenshtein distance to measure the similarity between the two results. We will also calculate a naive score using the `SequenceMatcher` from the `difflib` package, which is a simple measure of the similarity between two strings based on the number of matches in the longest common subsequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "def levenshtein_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate normalized Levenshtein distance\n",
    "    Returns value between 0 (completely different) and 1 (identical)\n",
    "    \"\"\"\n",
    "    distance = Levenshtein.distance(text1, text2)\n",
    "    max_len = max(len(text1), len(text2))\n",
    "    return 1 - (distance / max_len)\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "def simple_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate similarity ratio using SequenceMatcher\n",
    "    Returns value between 0 (completely different) and 1 (identical)\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, text1, text2).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13985705461925346"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_similarity(forecast_result_md, forecast_result_docling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17779960707269155"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_similarity(forecast_result_md, forecast_result_docling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the two results are quite different, with a similarity score of about 13.98% and 17.77% for Levenshtein and `SequenceMatcher` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docling's result is a quite readable markdown displaying key economic variables and their forecasts. Conversely, MarkItDown's result is a bit messy and hard to read but the information is there just not in a structured format. Does it matter? That's what we will explore next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Docling's result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## MARKETS IN REVIEW\n",
       "\n",
       "## Equities\n",
       "\n",
       "|                       | Total Return in USD (%)   | Total Return in USD (%)   | Total Return in USD (%)   | Total Return in USD (%)   |\n",
       "|-----------------------|---------------------------|---------------------------|---------------------------|---------------------------|\n",
       "|                       | Current                   | WTD                       | MTD                       | YTD                       |\n",
       "| DJIA                  | 43,828.06                 | -1.8                      | -2.3                      | 18.4                      |\n",
       "| NASDAQ                | 19,926.72                 | 0.4                       | 3.7                       | 33.7                      |\n",
       "| S&P 500               | 6,051.09                  | -0.6                      | 0.4                       | 28.6                      |\n",
       "| S&P 400 Mid Cap       | 3,277.20                  | -1.6                      | -2.6                      | 19.5                      |\n",
       "| Russell 2000          | 2,346.90                  | -2.5                      | -3.5                      | 17.3                      |\n",
       "| MSCI World            | 3,817.24                  | -1.0                      | 0.2                       | 22.1                      |\n",
       "| MSCI EAFE             | 2,319.05                  | -1.5                      | 0.2                       | 6.4                       |\n",
       "| MSCI Emerging Markets | 1,107.01                  | 0.3                       | 2.7                       | 10.6                      |\n",
       "\n",
       "## Fixed Income †\n",
       "\n",
       "|                              | Total Return in USD (%)   | Total Return in USD (%)   | Total Return in USD (%)   | Total Return in USD (%)   |\n",
       "|------------------------------|---------------------------|---------------------------|---------------------------|---------------------------|\n",
       "|                              | Current                   | WTD                       | MTD                       | YTD                       |\n",
       "| Corporate & Government       | 4.66                      | -1.34                     | -0.92                     | 1.94                      |\n",
       "| Agencies                     | 4.54                      | -0.58                     | -0.31                     | 3.35                      |\n",
       "| Municipals                   | 3.55                      | -0.87                     | -0.54                     | 1.99                      |\n",
       "| U.S. Investment Grade Credit | 4.79                      | -1.38                     | -0.93                     | 1.97                      |\n",
       "| International                | 5.17                      | -1.40                     | -0.90                     | 3.20                      |\n",
       "| High Yield                   | 7.19                      | -0.22                     | 0.20                      | 8.87                      |\n",
       "| 90 Day Yield                 | 4.32                      | 4.39                      | 4.49                      | 5.33                      |\n",
       "| 2 Year Yield                 | 4.24                      | 4.10                      | 4.15                      | 4.25                      |\n",
       "| 10 Year Yield                | 4.40                      | 4.15                      | 4.17                      | 3.88                      |\n",
       "| 30 Year Yield                | 4.60                      | 4.34                      | 4.36                      | 4.03                      |\n",
       "\n",
       "## Commodities & Currencies\n",
       "\n",
       "|                       | Total Return in USD (%)   | Total Return in USD (%)   | Total Return in USD (%)   | Total Return in USD (%)   |\n",
       "|-----------------------|---------------------------|---------------------------|---------------------------|---------------------------|\n",
       "| Commodities           | Current                   | WTD                       | MTD                       | YTD                       |\n",
       "| Bloomberg Commodity   | 237.90                    | 1.3                       | 0.7                       | 5.1                       |\n",
       "| WTI Crude $/Barrel †† | 71.29                     | 6.1                       | 4.8                       | -0.5                      |\n",
       "| Gold Spot $/Ounce ††  | 2648.23                   | 0.6                       | 0.2                       | 28.4                      |\n",
       "\n",
       "## Total Return in USD (%)\n",
       "\n",
       "| Currencies   |   Current |   Prior   Week End |   Prior   Month End |   2022   Year End |\n",
       "|--------------|-----------|--------------------|---------------------|-------------------|\n",
       "| EUR/USD      |      1.05 |               1.06 |                1.06 |              1.1  |\n",
       "| USD/JPY      |    153.65 |             150    |              149.77 |            141.04 |\n",
       "| USD/CNH      |      7.28 |               7.28 |                7.25 |              7.13 |\n",
       "\n",
       "## S&P Sector Returns\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Sources: Bloomberg, Factset. Total Returns from the period of 12/9/2024 to 12/13/2024. †Bloomberg Barclays Indices. ††Spot price returns. All data as of the 12/13/2024 close. Data would differ if a different time period was displayed. Short-term performance shown to illustrate more recent trend. Past performance is no guarantee\n",
       "\n",
       "of future results.\n",
       "\n",
       "## Economic Forecasts (as of 12/13/2024)\n",
       "\n",
       "|                                    | Q4 2024E   |   2024E | Q1 2025E   | Q2 2025E   | Q3 2025E   | Q4 2025E   |   2025E |\n",
       "|------------------------------------|------------|---------|------------|------------|------------|------------|---------|\n",
       "| Real global GDP (% y/y annualized) | -          |    3.1  | -          | -          | -          | -          |    3.2  |\n",
       "| Real U.S. GDP (% q/q annualized)   | 2.0        |    2.7  | 2.5        | 2.3        | 2.2        | 2.2        |    2.4  |\n",
       "| CPI inflation (% y/y)              | 2.7        |    2.9  | 2.3        | 2.3        | 2.7        | 2.5        |    2.5  |\n",
       "| Core CPI inflation (% y/y)         | 3.3        |    3.4  | 3.0        | 2.9        | 3.2        | 3.1        |    3    |\n",
       "| Unemployment rate (%)              | 4.2        |    4    | 4.3        | 4.3        | 4.4        | 4.4        |    4.3  |\n",
       "| Fed funds rate, end period (%)     | 4.38       |    4.38 | 4.13       | 3.88       | 3.88       | 3.88       |    3.88 |\n",
       "\n",
       "The forecasts in the table above are the base line view from BofA Global Research. The Global Wealth & Investment Management (GWIM) Investment Strategy Committee (ISC) may make adjustments to this view over the course of the year and can express upside/downside to these forecasts. Historical data is sourced from Bloomberg, FactSet, and\n",
       "\n",
       "Haver Analytics. There can be no assurance that the forecasts will be achieved. Economic or financial forecasts are inherently limited and should not be relied on as indicators of future investment performance.\n",
       "\n",
       "A = Actual. E/* = Estimate.\n",
       "\n",
       "Sources: BofA Global Research; GWIM ISC as of December 13, 2024.\n",
       "\n",
       "## Asset Class Weightings (as of 12/3/2024)\n",
       "\n",
       "|                                        | CIO View                     | CIO View    | CIO View   | CIO View   | CIO View   |\n",
       "|----------------------------------------|------------------------------|-------------|------------|------------|------------|\n",
       "| Asset Class                            | Underweight                  | Underweight | Neutral    | Overweight | Overweight |\n",
       "| Global Equities                        | slight over weight green    |            |           |            |           |\n",
       "| U.S. Large Cap Growth                  |                             |            |            |           |           |\n",
       "| U.S. Large Cap Value                   | Slight over weight green    |            |           |            |           |\n",
       "| U.S. Small Cap Growth                  | slight over weight green    |            |           |            |           |\n",
       "| U.S. Small Cap Value                   | slight over weight green    |            |           |            |           |\n",
       "| International Developed                | Slight underweight orange   |             |           |           |           |\n",
       "| Emerging Markets                       |                             |            |            |           |           |\n",
       "| Global Fixed Income                    | slight underweight orange   |             |           |           |           |\n",
       "| U.S. Governments                       | slight over weight green    |            |           |            |           |\n",
       "| U.S. Mortgages                         | Slight over weight green    |            |           |            |           |\n",
       "| U.S. Corporates                        | Slight underweight orange   |             |           |           |           |\n",
       "| International Fixed Income             |                             |            |            |           |           |\n",
       "| High Yield                             | Slight underweight orange   |             |           |           |           |\n",
       "| U.S. Investment-grade                  | Neutral yellow              |            |            |           |           |\n",
       "| Tax Exempt  U.S. High Yield Tax Exempt | Slight underweight orange   |             |           |           |           |\n",
       "| Cash                                   |                              |             |            |            |            |\n",
       "\n",
       "## CIO Equity Sector Views\n",
       "\n",
       "|                         | CIO View                     | CIO View    | CIO View   | CIO View   | CIO View   |\n",
       "|-------------------------|------------------------------|-------------|------------|------------|------------|\n",
       "| Sector                  |                              | Underweight | Neutral    |            | Overweight |\n",
       "| Utilities               | slight over weight green    |            |           |            |           |\n",
       "| Financials              | slight over weight green    |            |           |            |           |\n",
       "| Healthcare              | slight over weight green    |            |           |            |           |\n",
       "| Consumer  Discretionary | Slight over weight green    |            |           |            |           |\n",
       "| Information  Technology | Neutral yellow              |            |            |           |           |\n",
       "| Communication  Services | Neutral yellow              |            |            |           |           |\n",
       "| Industrials             | Neutral yellow              |            |            |           |           |\n",
       "| Real Estate             | Neutral yellow              |            |            |           |           |\n",
       "| Energy                  | slight underweight orange   |             |           |           |           |\n",
       "| Materials               | slight underweight orange   |             |           |           |           |\n",
       "| Consumer  Staples       | underweight red              |            |           |           |           |\n",
       "\n",
       "CIO asset class views are relative to the CIO Strategic Asset Allocation (SAA) of a multi-asset portfolio. Source: Chief Investment Office as of December 3, 2024. All sector and asset allocation recommendations must be considered in the context of an individual investor's goals, time horizon, liquidity needs and risk tolerance. Not all recommendations will be in the best interest of all investors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(forecast_result_docling))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MarkItDown's result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Economic Forecasts (as of 12/13/2024)\n",
       "\n",
       "Real global GDP (% y/y annualized)\n",
       "Real U.S. GDP (% q/q annualized)\n",
       "CPI inflation (% y/y)\n",
       "Core CPI inflation (% y/y)\n",
       "Unemployment rate (%)\n",
       "Fed funds rate, end period (%)\n",
       "\n",
       "Q4 2024E\n",
       "-\n",
       "2.0\n",
       "2.7\n",
       "3.3\n",
       "4.2\n",
       "4.38\n",
       "\n",
       "2024E\n",
       "3.1\n",
       "2.7\n",
       "2.9\n",
       "3.4\n",
       "4.0\n",
       "4.38\n",
       "\n",
       "Q1 2025E  Q2 2025E  Q3 2025E  Q4 2025E\n",
       "\n",
       "-\n",
       "2.5\n",
       "2.3\n",
       "3.0\n",
       "4.3\n",
       "4.13\n",
       "\n",
       "-\n",
       "2.3\n",
       "2.3\n",
       "2.9\n",
       "4.3\n",
       "3.88\n",
       "\n",
       "-\n",
       "2.2\n",
       "2.7\n",
       "3.2\n",
       "4.4\n",
       "3.88\n",
       "\n",
       "-\n",
       "2.2\n",
       "2.5\n",
       "3.1\n",
       "4.4\n",
       "3.88\n",
       "\n",
       "2025E\n",
       "3.2\n",
       "2.4\n",
       "2.5\n",
       "3.0\n",
       "4.3\n",
       "3.88\n",
       "\n",
       "The forecasts in the table above are the base line view f"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(forecast_result_md[:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's focus on the economic forecasts. In particular, we are interested in the CIO's 2025E forecasts.\n",
    "\n",
    "```{figure} ../data/input/2025.png\n",
    "---\n",
    "name: forecast2025\n",
    "alt: Forecast 2025\n",
    "scale: 60%\n",
    "align: center\n",
    "---\n",
    "Forecast 2025\n",
    "```\n",
    "\n",
    "We will define a `Forecast` pydantic model to represent an economic forecast composed of a `financial_variable` and a `financial_forecast`. We will also define a `EconForecast` pydantic model to represent the list of economic forecasts we want to extract from the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class Forecast(BaseModel):\n",
    "    financial_variable: str\n",
    "    financial_forecast: float\n",
    "class EconForecast(BaseModel):\n",
    "    forecasts: list[Forecast]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a simple function to extract the economic forecasts from the document using an LLM model (with structured output) using the following prompt template, where `extract_prompt` is kind of data the user would like to extract and `doc` is the input document to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "BASE_PROMPT = f\"\"\"\n",
    "    ROLE: You are an expert at structured data extraction. \n",
    "    TASK: Extract the following data {extract_prompt} from input DOCUMENT\n",
    "    FORMAT: The output should be a JSON object with 'financial_variable' as key and 'financial_forecast' as value.\n",
    "    \"\"\"\n",
    "prompt = f\"{BASE_PROMPT} \\n\\n DOCUMENT: {doc}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_doc(extract_prompt: str,  doc: str, client) -> EconForecast:\n",
    "    \"\"\"\n",
    "    Extract data of a financial document using an LLM model.\n",
    "    \n",
    "    Args:\n",
    "        doc: The financial document text to analyze\n",
    "        client: The LLM model to use for analysis\n",
    "        extract_prompt: The prompt to use for extraction\n",
    "        \n",
    "    Returns:\n",
    "        EconForecasts object containing sentiment analysis results\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_PROMPT = f\"\"\"\n",
    "    ROLE: You are an expert at structured data extraction. \n",
    "    TASK: Extract the following data {extract_prompt} from input DOCUMENT\n",
    "    FORMAT: The output should be a JSON object with 'financial_variable' as key and 'financial_forecast' as value.\n",
    "    \"\"\"\n",
    "    prompt = f\"{BASE_PROMPT} \\n\\n DOCUMENT: {doc}\"\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": doc}\n",
    "        ],\n",
    "        response_format=EconForecast\n",
    "    )\n",
    "    return completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user then calls the `extract_from_doc` function simply defining that \"Economic Forecasts for 2025E\" is the data they would like to extract from the document. We perform the extraction twice, once with MarkItDown and once with Docling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_prompt = \"Economic Forecasts for 2025E\"\n",
    "md_financials = extract_from_doc(extract_prompt, forecast_result_md, client)\n",
    "docling_financials = extract_from_doc(extract_prompt, forecast_result_docling, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response is a `EconForecast` object containing a list of `Forecast` objects. We can then convert the response to a pandas DataFrame for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EconForecast(forecasts=[Forecast(financial_variable='Real global GDP (% y/y annualized)', financial_forecast=3.2), Forecast(financial_variable='Real U.S. GDP (% q/q annualized)', financial_forecast=2.4), Forecast(financial_variable='CPI inflation (% y/y)', financial_forecast=2.5), Forecast(financial_variable='Core CPI inflation (% y/y)', financial_forecast=3.0), Forecast(financial_variable='Unemployment rate (%)', financial_forecast=4.3), Forecast(financial_variable='Fed funds rate, end period (%)', financial_forecast=3.88)])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_md_forecasts = pd.DataFrame([(f.financial_variable, f.financial_forecast) for f in md_financials.forecasts], \n",
    "                      columns=['Variable', 'Forecast'])\n",
    "df_docling_forecasts = pd.DataFrame([(f.financial_variable, f.financial_forecast) for f in docling_financials.forecasts], \n",
    "                      columns=['Variable', 'Forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real global GDP (% y/y annualized)</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real U.S. GDP (% q/q annualized)</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPI inflation (% y/y)</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core CPI inflation (% y/y)</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment rate (%)</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed funds rate, end period (%)</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Variable  Forecast\n",
       "0  Real global GDP (% y/y annualized)      3.20\n",
       "1    Real U.S. GDP (% q/q annualized)      2.40\n",
       "2               CPI inflation (% y/y)      2.50\n",
       "3          Core CPI inflation (% y/y)      3.00\n",
       "4               Unemployment rate (%)      4.30\n",
       "5      Fed funds rate, end period (%)      3.88"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_md_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real global GDP (% y/y annualized)</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real U.S. GDP (% q/q annualized)</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPI inflation (% y/y)</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core CPI inflation (% y/y)</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment rate (%)</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed funds rate, end period (%)</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Variable  Forecast\n",
       "0  Real global GDP (% y/y annualized)      3.20\n",
       "1    Real U.S. GDP (% q/q annualized)      2.40\n",
       "2               CPI inflation (% y/y)      2.50\n",
       "3          Core CPI inflation (% y/y)      3.00\n",
       "4               Unemployment rate (%)      4.30\n",
       "5      Fed funds rate, end period (%)      3.88"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docling_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from both MarkItDown and Docling are identical and accurately match the true values from the document. This demonstrates that despite MarkItDown's output appearing less readable from a human perspective, both approaches successfully extracted the economic forecast data with equal precision. The formatting differences between the two methods did not impact their ability to capture and structure the underlying information at least in this particular case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's focus on the asset class weightings. We will extract the asset class weightings from the document and compare the results from MarkItDown and Docling. The information now is presented in a quite different structure. The CIO view is represented in a spectrum from \"Underweight\", passing through \"Neutral\" to \"Overweight\". And the actual view is marked by some colored dots. Let's see if we can extract the information from the document.\n",
    "```{figure} ../data/input/asset_class.png\n",
    "---\n",
    "name: asset_class\n",
    "alt: Asset Class Weightings\n",
    "scale: 60%\n",
    "align: center\n",
    "---\n",
    "Asset Class Weightings\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user will simply define the following data to extract: \"Asset Class Weightings (as of 12/3/2024) in a scale from -2 to 2\". In that way, we expect that \"Underweight\" will be mapped to -2, \"Neutral\" to 0 and \"Overweight\" to 2 with some values in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_prompt = \"Asset Class Weightings (as of 12/3/2024) in a scale from -2 to 2\"\n",
    "asset_class_docling = extract_from_doc(extract_prompt, forecast_result_docling, client)\n",
    "asset_class_md = extract_from_doc(extract_prompt, forecast_result_md, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_md = pd.DataFrame([(f.financial_variable, f.financial_forecast) for f in asset_class_md.forecasts], \n",
    "                 columns=['Variable', 'Forecast'])\n",
    "df_docling = pd.DataFrame([(f.financial_variable, f.financial_forecast) for f in asset_class_docling.forecasts], \n",
    "                 columns=['Variable', 'Forecast'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a DataFrame to compare the results from MarkItDown and Docling with an added \"true_value\" column containing the true values from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>markitdown</th>\n",
       "      <th>docling</th>\n",
       "      <th>true_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Equities</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. Large Cap Growth</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Large Cap Value</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S. Small Cap Growth</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. Small Cap Value</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>International Developed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Emerging Markets</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global Fixed Income</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U.S. Governments</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U.S. Mortgages</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U.S. Corporates</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>International Fixed Income</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>High Yield</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>U.S. Investment-grade</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tax Exempt U.S. High Yield Tax Exempt</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 variable  markitdown  docling  true_value\n",
       "0                         Global Equities         1.0      1.0         1.0\n",
       "1                   U.S. Large Cap Growth         1.0      1.0         0.0\n",
       "2                    U.S. Large Cap Value         1.0      1.0         1.0\n",
       "3                   U.S. Small Cap Growth         1.0      1.0         1.0\n",
       "4                    U.S. Small Cap Value         1.0      1.0         1.0\n",
       "5                 International Developed         1.0     -1.0        -1.0\n",
       "6                        Emerging Markets         1.0      0.0         0.0\n",
       "7                     Global Fixed Income        -1.0     -1.0        -1.0\n",
       "8                        U.S. Governments        -1.0      1.0         1.0\n",
       "9                          U.S. Mortgages        -1.0      1.0         1.0\n",
       "10                        U.S. Corporates        -1.0     -1.0        -1.0\n",
       "11             International Fixed Income        -1.0      0.0         0.0\n",
       "12                             High Yield        -1.0     -1.0        -1.0\n",
       "13                  U.S. Investment-grade        -1.0      0.0         0.0\n",
       "14  Tax Exempt U.S. High Yield Tax Exempt        -1.0     -1.0        -1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame with specified columns\n",
    "df_comparison = pd.DataFrame({\n",
    "    'variable': df_docling['Variable'].iloc[:-1],\n",
    "    'markitdown': df_md['Forecast'],\n",
    "    'docling': df_docling['Forecast'].iloc[:-1],  # Drop last row\n",
    "    'true_value': [1.0, 0.0, 1.0, 1.0, 1.0, -1.0, 0.0, -1.0, 1.0, 1.0, -1.0, 0.0, -1.0, 0.0, -1.0]\n",
    "})\n",
    "\n",
    "display(df_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markitdown accuracy: 53.33%\n",
      "Docling accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for markitdown and docling\n",
    "markitdown_accuracy = (df_comparison['markitdown'] == df_comparison['true_value']).mean()\n",
    "docling_accuracy = (df_comparison['docling'] == df_comparison['true_value']).mean()\n",
    "\n",
    "print(f\"Markitdown accuracy: {markitdown_accuracy:.2%}\")\n",
    "print(f\"Docling accuracy: {docling_accuracy:.2%}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docling performs significantly better at 93.33% accuracy missing only one value. MarkItDown achieves 53.33% accuracy, struggling with nuanced asset class weightings. In this case, Docling's structured parsed output did help the LLM to extract the information more accurately compared to MarkItDown's unstructured output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to systematically extract all tables from the document? We can use Docling to do that by simply accessing the `tables` attribute of the `DocumentConverter` object.\n",
    "\n",
    "We observe that Docling extracted 7 tables from the document. Exporting tables from top down left to right in order of appearance.\n",
    "We can see the first table successfully extracted for Equities forecasts, the second one for Fixed Income forecasts. We also display the last table, which contains CIO Equity Sector Views.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_export_tables(file_path: Path) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Convert document and export tables to DataFrames.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to input document\n",
    "        \n",
    "    Returns:\n",
    "        List of pandas DataFrames containing the tables\n",
    "    \"\"\"\n",
    "    doc_converter = DocumentConverter()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    conv_res = doc_converter.convert(file_path)\n",
    "    \n",
    "    tables = []\n",
    "    # Export tables\n",
    "    for table in conv_res.document.tables:\n",
    "        table_df: pd.DataFrame = table.export_to_dataframe()\n",
    "        tables.append(table_df)\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"Document converted in {end_time:.2f} seconds.\")\n",
    "    \n",
    "    return tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and export tables\n",
    "tables = convert_and_export_tables(Path(FORECAST_FILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total Return in USD (%).Current</th>\n",
       "      <th>Total Return in USD (%).WTD</th>\n",
       "      <th>Total Return in USD (%).MTD</th>\n",
       "      <th>Total Return in USD (%).YTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DJIA</td>\n",
       "      <td>43,828.06</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>19,926.72</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S&amp;P 500</td>\n",
       "      <td>6,051.09</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>28.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S&amp;P 400 Mid Cap</td>\n",
       "      <td>3,277.20</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russell 2000</td>\n",
       "      <td>2,346.90</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSCI World</td>\n",
       "      <td>3,817.24</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSCI EAFE</td>\n",
       "      <td>2,319.05</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSCI Emerging Markets</td>\n",
       "      <td>1,107.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Total Return in USD (%).Current  \\\n",
       "0                   DJIA                       43,828.06   \n",
       "1                 NASDAQ                       19,926.72   \n",
       "2                S&P 500                        6,051.09   \n",
       "3        S&P 400 Mid Cap                        3,277.20   \n",
       "4           Russell 2000                        2,346.90   \n",
       "5             MSCI World                        3,817.24   \n",
       "6              MSCI EAFE                        2,319.05   \n",
       "7  MSCI Emerging Markets                        1,107.01   \n",
       "\n",
       "  Total Return in USD (%).WTD Total Return in USD (%).MTD  \\\n",
       "0                        -1.8                        -2.3   \n",
       "1                         0.4                         3.7   \n",
       "2                        -0.6                         0.4   \n",
       "3                        -1.6                        -2.6   \n",
       "4                        -2.5                        -3.5   \n",
       "5                        -1.0                         0.2   \n",
       "6                        -1.5                         0.2   \n",
       "7                         0.3                         2.7   \n",
       "\n",
       "  Total Return in USD (%).YTD  \n",
       "0                        18.4  \n",
       "1                        33.7  \n",
       "2                        28.6  \n",
       "3                        19.5  \n",
       "4                        17.3  \n",
       "5                        22.1  \n",
       "6                         6.4  \n",
       "7                        10.6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total Return in USD (%).Current</th>\n",
       "      <th>Total Return in USD (%).WTD</th>\n",
       "      <th>Total Return in USD (%).MTD</th>\n",
       "      <th>Total Return in USD (%).YTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corporate &amp; Government</td>\n",
       "      <td>4.66</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agencies</td>\n",
       "      <td>4.54</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Municipals</td>\n",
       "      <td>3.55</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S. Investment Grade Credit</td>\n",
       "      <td>4.79</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>International</td>\n",
       "      <td>5.17</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High Yield</td>\n",
       "      <td>7.19</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90 Day Yield</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.49</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 Year Yield</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10 Year Yield</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30 Year Yield</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Total Return in USD (%).Current  \\\n",
       "0        Corporate & Government                            4.66   \n",
       "1                      Agencies                            4.54   \n",
       "2                    Municipals                            3.55   \n",
       "3  U.S. Investment Grade Credit                            4.79   \n",
       "4                 International                            5.17   \n",
       "5                    High Yield                            7.19   \n",
       "6                  90 Day Yield                            4.32   \n",
       "7                  2 Year Yield                            4.24   \n",
       "8                 10 Year Yield                            4.40   \n",
       "9                 30 Year Yield                            4.60   \n",
       "\n",
       "  Total Return in USD (%).WTD Total Return in USD (%).MTD  \\\n",
       "0                       -1.34                       -0.92   \n",
       "1                       -0.58                       -0.31   \n",
       "2                       -0.87                       -0.54   \n",
       "3                       -1.38                       -0.93   \n",
       "4                       -1.40                       -0.90   \n",
       "5                       -0.22                        0.20   \n",
       "6                        4.39                        4.49   \n",
       "7                        4.10                        4.15   \n",
       "8                        4.15                        4.17   \n",
       "9                        4.34                        4.36   \n",
       "\n",
       "  Total Return in USD (%).YTD  \n",
       "0                        1.94  \n",
       "1                        3.35  \n",
       "2                        1.99  \n",
       "3                        1.97  \n",
       "4                        3.20  \n",
       "5                        8.87  \n",
       "6                        5.33  \n",
       "7                        4.25  \n",
       "8                        3.88  \n",
       "9                        4.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>CIO View.</th>\n",
       "      <th>CIO View.Underweight</th>\n",
       "      <th>CIO View.Neutral</th>\n",
       "      <th>CIO View.</th>\n",
       "      <th>CIO View.Overweight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Utilities</td>\n",
       "      <td>slight over weight green   </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financials</td>\n",
       "      <td>slight over weight green   </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Healthcare</td>\n",
       "      <td>slight over weight green   </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consumer  Discretionary</td>\n",
       "      <td>Slight over weight green  </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information  Technology</td>\n",
       "      <td>Neutral yellow  </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Communication  Services</td>\n",
       "      <td>Neutral yellow  </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Industrials</td>\n",
       "      <td>Neutral yellow  </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Neutral yellow  </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Energy</td>\n",
       "      <td>slight underweight orange  </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Materials</td>\n",
       "      <td>slight underweight orange  </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consumer  Staples</td>\n",
       "      <td>underweight red</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Sector                     CIO View.  \\\n",
       "0                 Utilities  slight over weight green      \n",
       "1                Financials  slight over weight green      \n",
       "2                Healthcare  slight over weight green      \n",
       "3   Consumer  Discretionary   Slight over weight green     \n",
       "4   Information  Technology             Neutral yellow     \n",
       "5   Communication  Services             Neutral yellow     \n",
       "6               Industrials             Neutral yellow     \n",
       "7               Real Estate             Neutral yellow     \n",
       "8                    Energy  slight underweight orange     \n",
       "9                 Materials  slight underweight orange     \n",
       "10        Consumer  Staples               underweight red   \n",
       "\n",
       "   CIO View.Underweight CIO View.Neutral CIO View. CIO View.Overweight  \n",
       "0                                                                    \n",
       "1                                                                    \n",
       "2                                                                    \n",
       "3                                                                    \n",
       "4                                                                    \n",
       "5                                                                    \n",
       "6                                                                    \n",
       "7                                                                    \n",
       "8                                                                    \n",
       "9                                                                    \n",
       "10                                                                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tables[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to MarkItDown, one interesting feature to explore is the ability to extract information from images by passing an image capable LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_llm = MarkItDown(llm_client=client, llm_model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = md_llm.convert(\"../data/input/forecast.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the description we obtain from the image of our input document. Overall, the description is somewhat accurate but contains a few inaccuracies including:\n",
    "\n",
    "- For the sector weightings, the description states there are \"underweight positions in U.S. Small Cap Growth\" but looking at the Asset Class Weightings chart, U.S. Small Cap Growth actually shows an overweight position (green circle).\n",
    "- The description mentions \"overweight positions in certain sectors such as Utilities and Financials\" but looking at the CIO Equity Sector Views, both these sectors show neutral positions, not overweight positions.\n",
    "- For fixed income, the description cites a \"10-Year (4.03%)\" yield, but the image shows the 30-Year Yield at 4.03%, while the 10-Year Yield is actually 4.40%.\n",
    "\n",
    "Arguably, the description's inaccuracies could be a consequence of the underlying LLM model's inability to process the image. Further research is needed to determine if this is the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Description:\n",
       "**Markets in Review: Economic Forecasts and Asset Class Weightings (as of 12/13/2024)**\n",
       "\n",
       "This detailed market overview presents key performance metrics and economic forecasts as of December 13, 2024.\n",
       "\n",
       "**Equities Overview:**\n",
       "- **Total Returns:** Highlights returns for major indices such as the DJIA (18.4% YTD), NASDAQ (33.7% YTD), and S&P 500 (28.6% YTD), showcasing strong performance across the board.\n",
       "- **Forecasts:** Economic indicators reveal a projected real global GDP growth of 3.1%, with inflation rates expected to stabilize around 2.2% in 2025. Unemployment rates are anticipated to remain low at 4.4%.\n",
       "\n",
       "**Fixed Income:**\n",
       "- Focuses on various segments, including Corporate & Government bonds, which offer an annualized return of 4.66% and indicate shifting trends in interest rates over 2-Year (4.25%) and 10-Year (4.03%) bonds.\n",
       "\n",
       "**Commodities & Currencies:**\n",
       "- Commodities such as crude oil and gold show varied performance, with oil increasing by 4.8% and gold prices sitting at $2,648.23 per ounce.\n",
       "- Currency metrics highlight the Euro and USD trends over the past year.\n",
       "\n",
       "**S&P Sector Returns:**\n",
       "- A quick reference for sector performance indicates a significant 2.5% return in Communication Services, while other sectors like Consumer Staples and Materials display minor fluctuations.\n",
       "\n",
       "**CIO Asset Class Weightings:**\n",
       "- Emphasizes strategic asset allocation recommendations which are crucial for an investor's portfolio. Underweight positions in U.S. Small Cap Growth and International Developed contrast with overweight positions in certain sectors such as Utilities and Financials, signaling tactical shifts based on ongoing economic assessments.\n",
       "\n",
       "**Note:** This summary is sourced from BofA Global Research and aims to provide a comprehensive view of current market conditions and forecasts to assist investors in making informed decisions.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result.text_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation\n",
    "\n",
    "RAG is a technique that allows LLMs to retrieve information from a knowledge base to answer questions. It is a popular technique for building LLM applications that require knowledge-intensive tasks.\n",
    "\n",
    "{cite}`lewis2021retrievalaugmentedgenerationknowledgeintensivenlp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Studies\n",
    "\n",
    "This section presents three case studies that demonstrate practical solutions to common LLM limitations:\n",
    "\n",
    "First, Content Chunking with Contextual Linking showcases how intelligent chunking strategies can overcome both context window and output token limitations. This case study illustrates techniques for breaking down and reassembling content while maintaining coherence, enabling the generation of high-quality long-form outputs despite model constraints.\n",
    "\n",
    "Second, a Retrieval Augmented Generation case study addresses the challenge of stale or outdated model knowledge. By implementing semantic search over a GitHub repository, this example demonstrates how to augment LLM responses with current, accurate information - allowing users to query and receive up-to-date answers about code repository contents.\n",
    "\n",
    "Third, the final case study builds a Quiz generator with citations. This case study explores some additional input management techniques that become particularly useful when long context window is available. This includes implementing prompt caching for efficiency and adding citations to enhance response accuracy and verifiability. These approaches show how to maximize the benefits of larger context models while maintaining response quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study I: Content Chunking with Contextual Linking\n",
    "\n",
    "Content chunking with contextual linking is a technique used to manage the `max_output_tokens` limitation by breaking down long-form content into smaller, manageable chunks while keeping chunk-specific context. This approach tackles three problems:\n",
    "1. The LLM's inability to process long inputs to do context-size limits\n",
    "2. The LLM's inability to generate long-form content due to the `max_output_tokens` limitation.\n",
    "3. The LLM's inability to maintain coherence and context when generating responses per chunks\n",
    "\n",
    "The following steps are followed to implement content chunking with contextual linking:\n",
    "1. **Chunking the Content**: The input content is split into smaller chunks. This allows the LLM to process each chunk individually, focusing on generating a complete and detailed response for that specific section of the input.\n",
    "\n",
    "2. **Maintaining Context**: Each chunk is linked with contextual information from the previous chunks. This helps in maintaining the flow and coherence of the content across multiple chunks.\n",
    "\n",
    "3. **Generating Linked Prompts**: For each chunk, a prompt is generated that includes the chunk's content and its context. This prompt is then used to generate the output for that chunk.\n",
    "\n",
    "4. **Combining the Outputs**: The outputs of all chunks are combined to form the final long-form content.\n",
    "\n",
    "Let's examine an example implementation of this technique.\n",
    "\n",
    "#### Generating long-form content\n",
    "\n",
    "- Goal: Generate a long-form report analyzing a company's financial statement.\n",
    "- Input: A company's 10K SEC filing.\n",
    "\n",
    "```{figure} ../_static/structured_output/diagram1.png\n",
    "---\n",
    "name: content-chunking-with-contextual-linking\n",
    "alt: Content Chunking with Contextual Linking\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "Content Chunking with Contextual Linking Schematic Representation.\n",
    "```\n",
    "\n",
    "The diagram in {numref}`content-chunking-with-contextual-linking` illustrates the process we will follow for handling long-form content generation with Large Language Models through \"Content Chunking with Contextual Linking.\" It shows how input content is first split into manageable chunks using a chunking function (e.g. `CharacterTextSplitter` with `tiktoken` tokenizer), then each chunk is processed sequentially while maintaining context from previous chunks. For each chunk, the system updates the context, generates a dynamic prompt with specific parameters, makes a call to the LLM chain, and stores the response. After all chunks are processed, the individual responses are combined with newlines to create the final report, effectively working around the token limit constraints of LLMs while maintaining coherence across the generated content.\n",
    "\n",
    "**Step 1: Chunking the Content**\n",
    "\n",
    "There are different methods for chunking, and each of them might be appropriate for different situations. However, we can broadly group chunking strategies in two types:\n",
    "- **Fixed-size Chunking**: This is the most common and straightforward approach to chunking. We simply decide the number of tokens in our chunk and, optionally, whether there should be any overlap between them. In general, we will want to keep some overlap between chunks to make sure that the semantic context doesn’t get lost between chunks. Fixed-sized chunking may be a reasonable path in many common cases. Compared to other forms of chunking, fixed-sized chunking is computationally cheap and simple to use since it doesn’t require the use of any specialied techniques or libraries.\n",
    "- **Content-aware Chunking**: These are a set of methods for taking advantage of the nature of the content we’re chunking and applying more sophisticated chunking to it. Examples include:\n",
    "  - **Sentence Splitting**: Many models are optimized for embedding sentence-level content. Naturally, we would use sentence chunking, and there are several approaches and tools available to do this, including naive splitting (e.g. splitting on periods), NLTK, and spaCy.\n",
    "  - **Recursive Chunking**: Recursive chunking divides the input text into smaller chunks in a hierarchical and iterative manner using a set of separators.\n",
    "  - **Semantic Chunking**: This is a class of methods that leverages embeddings to extract the semantic meaning present in your data, creating chunks that are made up of sentences that talk about the same theme or topic.\n",
    "\n",
    "  Here, we will utilize `langchain` for a content-aware sentence-splitting strategy for chunking. Langchain offers several text splitters {cite}`langchain_text_splitters` such as JSON-, Markdown- and HTML-based or split by token. We will use the `CharacterTextSplitter` with `tiktoken` as our tokenizer to count the number of tokens per chunk which we can use to ensure that we do not surpass the input token limit of our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(text: str, chunk_size: int, chunk_overlap: int) -> list:\n",
    "    \"\"\"\n",
    "    Split input text into chunks of specified size with specified overlap.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be chunked.\n",
    "        chunk_size (int): The maximum size of each chunk in tokens.\n",
    "        chunk_overlap (int): The number of tokens to overlap between chunks.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of text chunks.\n",
    "    \"\"\"\n",
    "    from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Writing the Base Prompt Template**\n",
    "\n",
    "We will write a base prompt template which will serve as a foundational structure for all chunks, ensuring consistency in the instructions and context provided to the language model. The template includes the following parameters:\n",
    "- `role`: Defines the role or persona the model should assume.\n",
    "- `context`: Provides the background information or context for the task.\n",
    "- `instruction`: Specifies the task or action the model needs to perform.\n",
    "- `input_text`: Contains the actual text input that the model will process.\n",
    "- `requirements`: Lists any specific requirements or constraints for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "def get_base_prompt_template() -> str:\n",
    "    \n",
    "    base_prompt = \"\"\"\n",
    "    ROLE: {role}\n",
    "    CONTEXT: {context}\n",
    "    INSTRUCTION: {instruction}\n",
    "    INPUT: {input}\n",
    "    REQUIREMENTS: {requirements}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(base_prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a simple function that returns an `LLMChain` which is a simple `langchain` construct that allows you to chain together a combination of prompt templates, language models and output parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "\n",
    "def get_llm_chain(prompt_template: str, model_name: str, temperature: float = 0):\n",
    "    \"\"\"\n",
    "    Returns an LLMChain instance using langchain.\n",
    "\n",
    "    Args:\n",
    "        prompt_template (str): The prompt template to use.\n",
    "        model_name (str): The name of the model to use.\n",
    "        temperature (float): The temperature setting for the model.\n",
    "\n",
    "    Returns:\n",
    "        llm_chain: An instance of the LLMChain.\n",
    "    \"\"\"\n",
    "    \n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv()\n",
    "    \n",
    "    api_key_label = model_name.split(\"/\")[0].upper() + \"_API_KEY\"\n",
    "    llm = ChatLiteLLM(\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        api_key=os.environ[api_key_label],\n",
    "    )\n",
    "    llm_chain = prompt_template | llm | StrOutputParser()\n",
    "    return llm_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Constructing Dynamic Prompt Parameters**\n",
    "\n",
    "Now, we will write a function (`get_dynamic_prompt_template`) that constructs prompt parameters dynamically for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def get_dynamic_prompt_params(prompt_params: Dict, \n",
    "                            part_idx: int, \n",
    "                            total_parts: int,\n",
    "                            chat_context: str,\n",
    "                            chunk: str) -> str:\n",
    "    \"\"\"\n",
    "    Construct prompt template dynamically per chunk while maintaining the chat context of the response generation.\n",
    "    \n",
    "    Args:\n",
    "        prompt_params (Dict): Original prompt parameters\n",
    "        part_idx (int): Index of current conversation part\n",
    "        total_parts (int): Total number of conversation parts\n",
    "        chat_context (str): Chat context from previous parts\n",
    "        chunk (str): Current chunk of text to be processed\n",
    "    Returns:\n",
    "        str: Dynamically constructed prompt template with part-specific params\n",
    "    \"\"\"\n",
    "    dynamic_prompt_params = prompt_params.copy()\n",
    "    # saves the chat context from previous parts\n",
    "    dynamic_prompt_params[\"context\"] = chat_context\n",
    "    # saves the current chunk of text to be processed as input\n",
    "    dynamic_prompt_params[\"input\"] = chunk\n",
    "    \n",
    "    # Add part-specific instructions\n",
    "    if part_idx == 0: # Introduction part\n",
    "        dynamic_prompt_params[\"instruction\"] = f\"\"\"\n",
    "        You are generating the Introduction part of a long report.\n",
    "        Don't cover any topics yet, just define the scope of the report.\n",
    "        \"\"\"\n",
    "    elif part_idx == total_parts - 1: # Conclusion part\n",
    "        dynamic_prompt_params[\"instruction\"] = f\"\"\"\n",
    "        You are generating the last part of a long report. \n",
    "        For this part, first discuss the below INPUT. Second, write a \"Conclusion\" section summarizing the main points discussed given in CONTEXT.\n",
    "        \"\"\"\n",
    "    else: # Main analysis part\n",
    "        dynamic_prompt_params[\"instruction\"] = f\"\"\"\n",
    "        You are generating part {part_idx+1} of {total_parts} parts of a long report.\n",
    "        For this part, analyze the below INPUT.\n",
    "        Organize your response in a way that is easy to read and understand either by creating new or merging with previously created structured sections given in CONTEXT.\n",
    "        \"\"\"\n",
    "    \n",
    "    return dynamic_prompt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Step 4: Generating the Report**\n",
    "\n",
    "Finally, we will write a function that generates the actual report by calling the `LLMChain` with the dynamically updated prompt parameters for each chunk and concatenating the results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(input_content: str, llm_model_name: str, \n",
    "                    role: str, requirements: str,\n",
    "                    chunk_size: int, chunk_overlap: int) -> str:\n",
    "    # stores the parts of the report, each generated by an individual LLM call\n",
    "    report_parts = [] \n",
    "    # split the input content into chunks\n",
    "    chunks = get_chunks(input_content, chunk_size, chunk_overlap)\n",
    "    # initialize the chat context with the input content\n",
    "    chat_context = input_content\n",
    "    # number of parts to be generated\n",
    "    num_parts = len(chunks)\n",
    "\n",
    "    prompt_params = {\n",
    "        \"role\": role, # user-provided\n",
    "        \"context\": \"\", # dinamically updated per part\n",
    "        \"instruction\": \"\", # dynamically updated per part\n",
    "        \"input\": \"\", # dynamically updated per part\n",
    "        \"requirements\": requirements #user-priovided\n",
    "    }\n",
    "\n",
    "    # get the LLMChain with the base prompt template\n",
    "    llm_chain = get_llm_chain(get_base_prompt_template(), \n",
    "                                 llm_model_name)\n",
    "\n",
    "    # dynamically update prompt_params per part\n",
    "    print(f\"Generating {num_parts} report parts\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        dynamic_prompt_params = get_dynamic_prompt_params(\n",
    "            prompt_params,\n",
    "            part_idx=i,\n",
    "            total_parts=num_parts,\n",
    "            chat_context=chat_context,\n",
    "            chunk=chunk\n",
    "        )\n",
    "        \n",
    "        # invoke the LLMChain with the dynamically updated prompt parameters\n",
    "        response = llm_chain.invoke(dynamic_prompt_params)\n",
    "\n",
    "        # update the chat context with the cummulative response\n",
    "        if i == 0:\n",
    "            chat_context = response\n",
    "        else:\n",
    "            chat_context = chat_context + response\n",
    "            \n",
    "        print(f\"Generated part {i+1}/{num_parts}.\")\n",
    "        report_parts.append(response)\n",
    "\n",
    "    report = \"\\n\".join(report_parts)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Usage**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text from sample 10K SEC filing\n",
    "with open('../data/apple.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk and chunk overlap size\n",
    "MAX_CHUNK_SIZE = 10000\n",
    "MAX_CHUNK_OVERLAP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = generate_report(text, llm_model_name=\"gemini/gemini-1.5-flash-latest\", \n",
    "                           role=\"Financial Analyst\", \n",
    "                           requirements=\"The report should be in a readable, structured format, easy to understand and follow. Focus on finding risk factors and market moving insights.\",\n",
    "                           chunk_size=MAX_CHUNK_SIZE, \n",
    "                           chunk_overlap=MAX_CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated report to a local file\n",
    "with open('data/apple_report.txt', 'w') as file:\n",
    "    file.write(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Introduction**\n",
       "\n",
       "This report provides a comprehensive analysis of Apple Inc.'s financial performance and position for the fiscal year ended September 28, 2024, as disclosed in its Form 10-K filing with the United States Securities and Exchange Commission.  The analysis will focus on identifying key risk factors impacting Apple's business, evaluating its financial health, and uncovering market-moving insights derived from the provided data.  The report will delve into Apple's various segments, product lines, and services, examining their performance and contributions to overall financial results.  Specific attention will be paid to identifying trends, potential challenges, and opportunities for future growth.  The analysis will also consider the broader macroeconomic environment and its influence on Apple's operations and financial outlook.  Finally, the report will incorporate relevant information from Apple's definitive proxy statement for its 2025 annual meeting of shareholders, as incorporated by reference in the Form 10-K.\n",
       "\n",
       "**PART 2: Key Risk Factors and Market-Moving Insights**\n",
       "\n",
       "This section analyzes key risk factors disclosed in Apple Inc.'s 2024 Form 10-K, focusing on their potential impact on financial performance and identifying potential market-moving insights.  The analysis is structured around the major risk categories identified in the filing.\n",
       "\n",
       "**2.1 Dependence on Third-Party Developers:**\n",
       "\n",
       "Apple's success is heavily reliant on the continued support and innovation of third-party software developers.  The Form 10-K highlights several critical aspects of this dependence:\n",
       "\n",
       "* **Market Share Vulnerability:** Apple's relatively smaller market share in smartphones, personal computers, and tablets compared to competitors (Android, Windows, gaming consoles) could discourage developers from prioritizing Apple's platform, leading to fewer high-quality apps and potentially impacting customer purchasing decisions.  This is a significant risk, especially given the rapid pace of technological change.  A decline in app availability or quality could negatively impact sales and market share.  **Market-moving insight:**  Monitoring developer activity and app quality across competing platforms is crucial for assessing this risk.  Any significant shift in developer focus away from iOS could be a negative market signal.\n",
       "\n",
       "* **App Store Dynamics:** While Apple allows developers to retain most App Store revenue, its commission structure and recent changes (e.g., complying with the Digital Markets Act (DMA) in the EU) introduce uncertainty.  Changes to the App Store's policies or fee structures could materially affect Apple's revenue and profitability.  **Market-moving insight:**  Closely monitoring regulatory developments (especially concerning the DMA) and their impact on App Store revenue is essential.  Any significant changes to Apple's App Store policies or revenue streams could trigger market reactions.\n",
       "\n",
       "* **Content Acquisition and Creation:** Apple's reliance on third-party digital content providers for its services introduces risks related to licensing agreements, competition, and pricing.  The cost of producing its own digital content is also increasing due to competition for talent and subscribers.  Failure to secure or create appealing content could negatively impact user engagement and revenue.  **Market-moving insight:**  Analyzing the success of Apple's original content initiatives and the renewal rates of third-party content agreements will provide insights into this risk.\n",
       "\n",
       "**2.2 Operational Risks:**\n",
       "\n",
       "Several operational risks could significantly impact Apple's performance:\n",
       "\n",
       "* **Employee Retention:**  Competition for highly skilled employees, particularly in Silicon Valley, poses a significant risk.  Failure to retain key personnel or maintain its distinctive culture could negatively affect innovation, product development, and overall operational efficiency.  **Market-moving insight:**  Any significant changes in employee turnover rates or negative press regarding Apple's workplace culture could negatively impact investor sentiment.\n",
       "\n",
       "* **Reseller Dependence:** Apple's reliance on carriers, wholesalers, and retailers for product distribution introduces risks related to their financial health, distribution decisions, and potential changes in financing or subsidy programs.  **Market-moving insight:**  Monitoring the financial performance of key resellers and any changes in their distribution strategies is crucial.\n",
       "\n",
       "* **Information Technology and Cybersecurity:**  Apple's dependence on complex IT systems makes it vulnerable to system failures, network disruptions, and cybersecurity threats (including ransomware attacks).  These events could disrupt operations, damage reputation, and impact sales.  The Form 10-K highlights the company's proactive measures, but acknowledges that these may not be sufficient to prevent all incidents.  **Market-moving insight:**  Any major cybersecurity breach or significant service outage could trigger a negative market reaction.\n",
       "\n",
       "**2.3 Legal and Regulatory Risks:**\n",
       "\n",
       "Apple faces significant legal and regulatory challenges:\n",
       "\n",
       "* **Antitrust Litigation:**  The ongoing antitrust lawsuits in the U.S. and investigations in Europe concerning App Store practices pose a substantial risk.  Adverse outcomes could result in significant fines, changes to business practices, and reputational damage.  **Market-moving insight:**  The progress and outcomes of these legal proceedings will be closely watched by the market.  Any negative developments could significantly impact Apple's stock price.\n",
       "\n",
       "* **Digital Markets Act (DMA) Compliance:**  Apple's efforts to comply with the DMA in the EU introduce uncertainty and potential costs.  Non-compliance could lead to substantial fines.  **Market-moving insight:**  The Commission's ongoing investigations and any subsequent decisions will be closely monitored.\n",
       "\n",
       "* **Data Privacy and Protection:**  Increasingly stringent data privacy regulations worldwide impose significant compliance costs and risks.  Non-compliance could result in penalties and reputational harm.  **Market-moving insight:**  Any significant fines or negative publicity related to data privacy violations could negatively impact Apple's stock price.\n",
       "\n",
       "* **Other Legal Proceedings:**  The Form 10-K notes that Apple is subject to various other legal proceedings, the outcomes of which are uncertain and could materially affect its financial condition.\n",
       "\n",
       "**2.4 Financial Risks:**\n",
       "\n",
       "Several financial risks could impact Apple's performance:\n",
       "\n",
       "* **Sales and Profit Margin Volatility:**  Apple's quarterly net sales and profit margins are subject to fluctuations due to various factors, including pricing pressures, competition, product life cycles, supply chain issues, and macroeconomic conditions.  **Market-moving insight:**  Any significant deviation from expected sales or profit margins could trigger market reactions.\n",
       "\n",
       "* **Foreign Exchange Rate Fluctuations:**  Apple's international operations expose it to risks associated with changes in the value of the U.S. dollar.  Fluctuations in exchange rates can impact sales, earnings, and gross margins.  **Market-moving insight:**  Significant movements in major currency exchange rates relative to the USD should be monitored for their potential impact on Apple's financial results.\n",
       "\n",
       "* **Credit Risk and Investment Portfolio:**  Apple's exposure to credit risk on trade receivables and fluctuations in the value of its investment portfolio could lead to losses.  **Market-moving insight:**  Any significant deterioration in the creditworthiness of key customers or a substantial decline in the value of Apple's investment portfolio could be viewed negatively by the market.\n",
       "\n",
       "* **Tax Risks:**  Changes in tax rates, new tax legislation, and tax audits could materially affect Apple's financial performance.\n",
       "\n",
       " (...) \n",
       "\n",
       " **4.10 Debt and Share Repurchases:**\n",
       "\n",
       "Note 9 details Apple's debt structure, including commercial paper and term debt.  While the company has a strong credit rating, the significant amount of debt and the high weighted-average interest rate on commercial paper (5.00% in 2024) indicate potential interest rate risk.  Note 10 highlights the substantial share repurchase program ($95 billion in 2024), which, while returning value to shareholders, could limit funds available for future investments or acquisitions.  **Market-moving insight:**  Investors will monitor the balance between debt levels, share repurchases, and investments in future growth.\n",
       "\n",
       "**4.11 Share-Based Compensation:**\n",
       "\n",
       "Note 11 shows a steady increase in share-based compensation expense, reflecting Apple's reliance on equity-based incentives to attract and retain talent.  The significant unrecognized compensation cost related to outstanding RSUs ($19.4 billion in 2024) represents a future expense commitment.  **Market-moving insight:**  Changes in share-based compensation policies or unexpected increases in expense could impact future profitability.\n",
       "\n",
       "**4.12 Commitments and Supply Concentrations:**\n",
       "\n",
       "Note 12 reveals Apple's substantial unconditional purchase obligations, primarily for suppliers, licensed intellectual property, and content.  These commitments represent significant future cash outflows and highlight the company's dependence on its supply chain.  **Market-moving insight:**  Any disruptions in the supply chain or changes in supplier relationships could negatively impact Apple's production and sales.\n",
       "\n",
       "\n",
       "This detailed analysis reveals several key risk factors and market-moving insights beyond those identified in Part 3.  Investors and analysts should carefully consider these factors when assessing Apple's future performance and valuation.\n",
       "\n",
       "**PART 5: Contingencies, Supply Chain, and Segment Analysis**\n",
       "\n",
       "This section analyzes additional information from Apple Inc.'s 2024 Form 10-K, focusing on contingencies, supply chain risks, and a deeper dive into segment performance.\n",
       "\n",
       "**5.1 Contingencies and Legal Proceedings:**\n",
       "\n",
       "The Form 10-K acknowledges that Apple is involved in various legal proceedings and claims. While management believes no material loss is reasonably possible beyond existing accruals, the inherent uncertainty of litigation remains a risk.  Adverse outcomes in any of these cases could negatively impact Apple's financial condition and reputation.  **Market-moving insight:**  Any significant legal developments or settlements should be closely monitored for their potential market impact.  Increased legal expenses or negative publicity could affect investor sentiment.\n",
       "\n",
       "**5.2 Supply Chain Concentration:**\n",
       "\n",
       "Apple's reliance on a concentrated network of outsourcing partners, primarily located in a few Asian countries, presents significant risks.  The dependence on single or limited sources for certain custom components exposes Apple to supply chain disruptions, shortages, and price fluctuations.  While Apple uses multiple sources for most components, the unique nature of some components used in new products creates vulnerability.  Suppliers might prioritize common components over custom ones, impacting Apple's ability to produce its innovative products.  **Market-moving insight:**  Any significant supply chain disruptions, geopolitical instability in key manufacturing regions, or changes in supplier relationships could negatively impact Apple's production and sales, triggering a negative market reaction.\n",
       "\n",
       "**5.3 Detailed Segment Analysis:**\n",
       "\n",
       "Note 13 provides a detailed breakdown of Apple's segment performance.  While the Americas and Europe showed growth, primarily driven by Services revenue, Greater China experienced a decline due to lower iPhone and iPad sales and currency headwinds.  This highlights the regional economic and currency risks impacting Apple's revenue.  The relatively flat year-over-year iPhone sales, despite growth in other product lines, warrants further investigation into market saturation and competitive pressures.  The significant contribution of the Services segment to overall revenue and profitability underscores both its importance and the risk associated with its dependence on this segment.\n",
       "\n",
       "The reconciliation of segment operating income to consolidated operating income reveals that research and development (R&D) and other corporate expenses significantly impact overall profitability.  While increased R&D is generally positive, it reduces short-term profits.  The geographical breakdown of net sales and long-lived assets further emphasizes the concentration of Apple's business in the U.S. and China.  **Market-moving insight:**  Continued weakness in the Greater China market, sustained flat iPhone sales, or any significant changes in R&D spending should be closely monitored for their potential impact on Apple's financial performance and investor sentiment.\n",
       "\n",
       "\n",
       "**5.4 Auditor's Report and Internal Controls:**\n",
       "\n",
       "The auditor's report expresses an unqualified opinion on Apple's financial statements and internal control over financial reporting.  However, it identifies uncertain tax positions as a critical audit matter.  The significant amount of unrecognized tax benefits ($22.0 billion) and the complexity involved in evaluating these positions highlight a substantial risk.  Management's assessment of these positions involves significant judgment and relies on interpretations of complex tax laws.  Apple's management also asserts that its disclosure controls and procedures are effective.  **Market-moving insight:**  Any changes in tax laws, unfavorable rulings on uncertain tax positions, or weaknesses in internal controls could materially affect Apple's financial results and investor confidence.\n",
       "\n",
       "\n",
       "**Conclusion**\n",
       "\n",
       "This report provides a comprehensive analysis of Apple Inc.'s financial performance and position for fiscal year 2024.  While Apple maintains a strong financial position with substantial cash reserves and a robust capital return program, several key risk factors could significantly impact its future performance.  These risks include:\n",
       "\n",
       "* **Dependence on third-party developers:**  A shift in developer focus away from iOS or changes to the App Store's policies could negatively impact Apple's revenue and profitability.\n",
       "* **Operational risks:**  Employee retention challenges, reseller dependence, and cybersecurity threats pose significant operational risks.\n",
       "* **Legal and regulatory risks:**  Ongoing antitrust litigation, the Digital Markets Act (DMA) compliance, and data privacy regulations introduce substantial legal and regulatory uncertainties.\n",
       "* **Financial risks:**  Volatility in sales and profit margins, foreign exchange rate fluctuations, credit risk, and tax risks could impact Apple's financial performance.\n",
       "* **Supply chain concentration:**  Apple's reliance on a concentrated network of outsourcing partners, primarily located in a few Asian countries, and dependence on single or limited sources for certain custom components, exposes the company to significant supply chain risks.\n",
       "* **Uncertain tax positions:**  The significant amount of unrecognized tax benefits represents a substantial uncertainty that could materially affect Apple's financial results.\n",
       "\n",
       "Despite these risks, Apple's strong liquidity position, continued growth in its Services segment, and robust capital return program provide a degree of resilience.  However, investors and analysts should closely monitor the market-moving insights identified throughout this report, including developer activity, regulatory developments, regional economic conditions, supply chain stability, and the resolution of uncertain tax positions, to assess their potential impact on Apple's future performance and valuation.  The significant short-term obligations, while manageable given Apple's cash position, highlight the need for continued financial discipline and effective risk management.  A deeper, more granular analysis of the financial statements and notes is recommended for a more complete assessment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and display the generated report\n",
    "with open('../data/apple_report.txt', 'r') as file:\n",
    "    report_content = file.read()\n",
    "    \n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Display first and last 25% of the report content\n",
    "report_lines = report_content.splitlines()\n",
    "total_lines = len(report_lines)\n",
    "quarter_lines = total_lines // 4\n",
    "\n",
    "top_portion = '\\n'.join(report_lines[:quarter_lines])\n",
    "bottom_portion = '\\n'.join(report_lines[-quarter_lines:])\n",
    "\n",
    "display(Markdown(f\"{top_portion}\\n\\n (...) \\n\\n {bottom_portion}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Results from the generated report present a few interesting aspects:\n",
    "\n",
    "- **Coherence**: The generated report demonstrates an apparent level of coherence. The sections are logically structured, and the flow of information is smooth. Each part of the report builds upon the previous sections, providing a comprehensive analysis of Apple Inc.'s financial performance and key risk factors. The use of headings and subheadings helps in maintaining clarity and organization throughout the document.\n",
    "\n",
    "- **Adherence to Instructions**: The LLM followed the provided instructions effectively. The report is in a readable, structured format, and it focuses on identifying risk factors and market-moving insights as requested. The analysis is detailed and covers various aspects of Apple's financial performance, including revenue segmentation, profitability, liquidity, and capital resources. The inclusion of market-moving insights adds value to the report, aligning with the specified requirements.\n",
    "\n",
    "Despite the seemingly good quality of the results, there are some limitations to consider:\n",
    "\n",
    "- **Depth of Analysis**: While the report covers a wide range of topics, the depth of analysis in certain sections may not be as comprehensive as a human expert's evaluation. Some nuances and contextual factors might be overlooked by the LLM. Splitting the report into multiple parts helps in mitigating this issue.\n",
    "\n",
    "- **Chunking Strategy**: The current approach splits the text into chunks based on size, which ensures that each chunk fits within the model's token limit. However, this method may disrupt the logical flow of the document, as sections of interest might be split across multiple chunks. An alternative approach could be \"structured\" chunking, where the text is divided based on meaningful sections or topics. This would preserve the coherence of each section, making it easier to follow and understand. Implementing structured chunking requires additional preprocessing to identify and segment the text appropriately, but it can significantly enhance the readability and logical flow of the generated report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study II: Github RAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study III: Quiz Generation with Citations\n",
    "\n",
    "In this case study, we will build a Quiz generator with citations that explores additional input management techniques particularly useful with long context windows. The implementation includes prompt caching for efficiency and citation tracking to enhance accuracy and verifiability. We will use Gemini 1.5 Pro as our LLM model, which has a context window of 2M tokens.\n",
    "\n",
    "#### Use Case\n",
    "\n",
    "Let's assume you are a Harvard student enrolled in GOV 1039 \"The Birth of Modern Democracy\" (see {numref}`harvard-class`), you face a daunting reading list for next Tuesday's class on Rights. The readings include foundational documents like the Magna Carta, Declaration of Independence, and US Bill of Rights, each with specific sections to analyze.\n",
    "\n",
    "```{figure} ../_static/input/harvard.png\n",
    "---\n",
    "name: harvard-class\n",
    "alt: Harvard Class\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "Harvard's Democratic Theory Class\n",
    "```\n",
    "\n",
    "Instead of trudging through these dense historical texts sequentially, we would like to:\n",
    "- Extract key insights and connections between these documents, conversationally.\n",
    "- Engage with the material through a quiz format.\n",
    "- Add citations to help with verifying answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "\n",
    "The full implementation is available at Book's [Github repository](https://github.com/souzatharsis/tamingLLMs/tamingllms/notebooks/src/gemini_duo.py). Here, we will cover the most relevant parts of the implementation.\n",
    "\n",
    "**Client Class**\n",
    "\n",
    "First, we will define the `Client` class which will provide the key interface users will interact with. It has the following summarized interface:\n",
    "\n",
    "- Initialization:\n",
    "    - `__init__(knowledge_base: List[str] = [])`: Initialize with optional list of URLs as knowledge base\n",
    "\n",
    "- Core Methods:\n",
    "    - `add_knowledge_base(urls: List[str]) -> None`: Add URLs to the knowledge base\n",
    "    - `add(urls: List[str]) -> None`: Extract content from URLs and add to conversation input\n",
    "    - `msg(msg: str = \"\", add_citations: bool = False) -> str`: Enables users to send messages to the client\n",
    "    - `quiz(add_citations: bool = True, num_questions: int = 10) -> str`: Generate a quiz based on full input memory\n",
    "\n",
    "- Key Attributes:\n",
    "    - `knowledge_base`: List of URLs providing foundation knowledge\n",
    "    - `input`: Current input being studied (short-term memory)\n",
    "    - `input_memory`: Cumulative input + knowledge base (long-term memory) \n",
    "    - `response`: Latest response from LLM\n",
    "    - `response_memory`: Cumulative responses (long-term memory)\n",
    "    - `urls_memory`: Cumulative list of processed URLs\n",
    "\n",
    "\n",
    "**Corpus-in-Context Prompting**\n",
    "\n",
    "The `add()` method is key since it is used to add content to the client. It takes a list of URLs and extracts the content from each URL using a content extractor, which we used MarkitDown. The content is then added to the conversation input in a way that enables citations using the \"Corpus-in-Context\" (CIC) Prompting {cite}`lee2024longcontextlanguagemodelssubsume`.\n",
    "\n",
    "{numref}`cic` shows how CIC format is used to enable citations. It inserts a corpus into the prompt. Each candidate citable part (e.g., passage, chapter) in a corpus is assigned a unique identifier (ID) that can be referenced as needed for that task.\n",
    "\n",
    "```{figure} ../_static/input/cic.png\n",
    "---\n",
    "name: cic\n",
    "alt: CIC Format\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "Example of Corpus-in-Context Prompting for retrieval. \n",
    "```\n",
    "\n",
    "CiC prompting leverages LLM's capacity to follow instructions by carefully annotating the corpus with document IDs. It benefits from a strong, capable models to retrieve over large corpora provided in context. \n",
    "\n",
    "```python\n",
    "    def add(self, urls: List[str]) -> None:\n",
    "        self.urls = urls\n",
    "\n",
    "        # Add new content to input following CIC format to enable citations\n",
    "        for url in urls:\n",
    "            self.urls_memory.append(url)\n",
    "            content = self.extractor.convert(url).text_content\n",
    "            formatted_content = f\"ID: {self.reference_id} | {content} | END ID: {self.reference_id}\"\n",
    "            self.input += formatted_content + \"\\n\" \n",
    "            self.reference_id += 1\n",
    "        \n",
    "        # Update memory\n",
    "        self.input_memory = self.input_memory + self.input\n",
    "```\n",
    "\n",
    "The method `add_knowledge_base()` is a simple wrapper around the `add()` method. It is used to add URLs to the knowledge base, which are later cached by the LLM model as we will see later.\n",
    "\n",
    "```python\n",
    "    def add_knowledge_base(self, urls: List[str]) -> None:\n",
    "        self.add(urls)\n",
    "```\n",
    "\n",
    "\n",
    "Later, when the user sends a message to the client, the `msg()` method is used to generate a response  while enabling citations. `self.content_generator` is an instance of our LLM model, which we will next.\n",
    "\n",
    "```python\n",
    "    def msg(self, msg: str = \"\", add_citations: bool = False) -> str:\n",
    "        if add_citations:\n",
    "            msg = msg + \"\\n\\n For key statements, add Input ID to the response.\"\n",
    "\n",
    "        self.response = self.content_generator.generate(\n",
    "            input_content=self.input,\n",
    "            user_instructions=msg\n",
    "        )\n",
    "\n",
    "        self.response_memory = self.response_memory + self.response.text\n",
    "\n",
    "        return self.response.text\n",
    "```\n",
    "\n",
    "**Prompt Caching**\n",
    "\n",
    "LLM-based applications often involve repeatedly passing the same input tokens to a model, which can be inefficient and costly. Context caching addresses this by allowing you to cache input tokens after their first use and reference them in subsequent requests. This approach significantly reduces costs compared to repeatedly sending the same token corpus, especially at scale.\n",
    "\n",
    "Context caching proves especially valuable when a large initial context needs to be referenced multiple times by smaller requests. By caching the context upfront, these applications can maintain high performance while optimizing token usage and associated costs.\n",
    "\n",
    "In our application, the user might pass a large knowledge base to the client that can be referenced multiple times by smaller user requests. Our `Client` class is composed of a `LLMBackend` class that takes the `input_memory` - containing the entire knowledge base and any additional user added content.\n",
    "```python\n",
    "self.llm = LLMBackend(input=self.input_memory)\n",
    "```\n",
    "\n",
    "In our `LLMBackend` Class, we leverage prompt caching on input tokens and uses them for subsequent requests.\n",
    "\n",
    "```python\n",
    "class LLMBackend:\n",
    "    def __init__(self, model_name: str, input: str, cache_ttl: int = 60):\n",
    "        self.cache = caching.CachedContent.create(\n",
    "            model=model_name,\n",
    "            display_name='due_knowledge_base', # used to identify the cache\n",
    "            system_instruction=(\n",
    "            self.compose_prompt(input, conversation_config)\n",
    "        ),\n",
    "        ttl=datetime.timedelta(minutes=cache_ttl),\n",
    "    )\n",
    "\n",
    "    self.model = genai.GenerativeModel.from_cached_content(cached_content=self.cache)\n",
    "```\n",
    "\n",
    "**Quiz Generation**\n",
    "\n",
    "Coming back to our `Client` class, we implement the `quiz()` method to generate a quiz based on the full input memory, i.e. the initial knowledge base and any additional user added content.\n",
    "\n",
    "The `quiz()` method returns a `Quiz` instance which behind the scenes caches input tokens. The user later can invoke the `generate()` method to generate a quiz passing the user instructions in `msg` parameter, as we will see later.\n",
    "\n",
    "```python\n",
    "    def quiz(self, add_citations: bool = True, num_questions: int = 10) -> str:\n",
    "        \"\"\"\n",
    "        Returns a quiz instance based on full input memory.\n",
    "        \"\"\"\n",
    "        self.quiz_instance = Quiz(\n",
    "                         input=self.input_memory,\n",
    "                         add_citations=add_citations,\n",
    "                         num_questions=num_questions)\n",
    "        return self.quiz_instance\n",
    "```\n",
    "\n",
    "We write a simple prompt template for quiz generation:\n",
    "\n",
    "> ROLE:\n",
    "> - You are a Harvard Professor providing a quiz.\n",
    "> INSTRUCTIONS:\n",
    "> - Generate a quiz with {num_questions} questions based on the input.\n",
    "> - The quiz should be multi-choice.\n",
    "> - Answers should be provided at the end of the quiz.\n",
    "> - Questions should have broad coverage of the input including multiple Input IDs.\n",
    "> - Level of difficulty is advanced/hard.\n",
    "> - {citations}\n",
    "> STRUCTURE:\n",
    "> - Sequence of questions and alternatives.\n",
    "> - At the end provide the correct answers.\n",
    "\n",
    "where, `{citations}` instructs the model to add CiC citations to the response if user requests it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Usage\n",
    "\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "First, we will define our knowledge base. \n",
    "\n",
    "- Harvard Class: [GOV 1039 Syllabus](https://scholar.harvard.edu/files/dlcammack/files/gov_1039_syllabus.pdf)\n",
    "- Class / Topic: \"Rights\"\n",
    "- Reading List:\n",
    "    - ID 1. The Declaration of Independence of the United States of America\n",
    "    - ID 2. The United States Bill of Rights\n",
    "    - ID 3. John F. Kennedy's Inaugural Address\n",
    "    - ID 4. Lincoln's Gettysburg Address\n",
    "    - ID 5. The United States Constitution\n",
    "    - ID 6. Give Me Liberty or Give Me Death\n",
    "    - ID 7. The Mayflower Compact\n",
    "    - ID 8. Abraham Lincoln's Second Inaugural Address\n",
    "    - ID 9. Abraham Lincoln's First Inaugural Address\n",
    "\n",
    "We will take advantage of Project Gutenberg's to create our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = [f\"https://www.gutenberg.org/cache/epub/{i}/pg{i}.txt\" for i in range(1,9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import our module as `genai_duo` and initialize the `Client` class with our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemini_duo as genai_duo\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duo = genai_duo.Client(knowledge_base=kb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we converted each book into markdown using MarkitDown and cached the content in our LLM model. We can access how many tokens we have cached in our LLM model by looking at the `usage_metadata` attribute of the Gemini's model response. At this point, we have cached at total of 38470 tokens.\n",
    "\n",
    "Now, we can add references to our knowledge base at anytime by calling the `add()` method. We add the following references:\n",
    "1. The Magna Carta\n",
    "2. William Shap McKechnie on Magna Carta book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_references = [\"https://www.gutenberg.org/cache/epub/10000/pg10000.txt\", \"https://www.gutenberg.org/cache/epub/65363/pg65363.txt\"]\n",
    "\n",
    "duo.add(study_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate a `Quiz` object and generate a quiz based on the full input memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = duo.quiz(add_citations=True)\n",
    "display(Markdown(quiz.generate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{numref}`quiz` shows a sample sample quiz with citations. Marked in yellow are the citations which refer to the input IDs of the resources we added to the model.\n",
    "\n",
    "```{figure} ../_static/input/quiz.png\n",
    "---\n",
    "name: quiz\n",
    "alt: Quiz with Citations\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "Sample Quiz with Citations.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "The experiment demonstrated the ability to build a knowledge base from multiple sources and generate quizzes with citations. The system successfully ingested content from Project Gutenberg texts, including historical documents like the Magna Carta, and used them to create interactive educational content.\n",
    "\n",
    "However, several limitations emerged during this process:\n",
    "\n",
    "1. Memory Management: The system currently loads all content into memory, which could become problematic with larger knowledge bases. A more scalable approach might involve chunking or streaming the content.\n",
    "\n",
    "2. Context Window Constraints: With 38,470 tokens cached, we are approaching typical context window limits of many LLMs. This restricts how much knowledge can be referenced simultaneously during generation.\n",
    "\n",
    "3. Citation Quality: While the system provides citations, they lack specificity - pointing to entire documents rather than specific passages or page numbers. This limits the ability to fact-check or verify specific claims.\n",
    "\n",
    "4. Content Verification: The system does not currently verify the accuracy of generated quiz questions against the source material. This could lead to potential hallucinations or misinterpretations.\n",
    "\n",
    "5. Input Format Limitations: The current implementation works well with plain text but may struggle with more complex document formats or structured data sources.\n",
    "\n",
    "These limitations highlight opportunities for future improvements in knowledge management and citation systems when building LLM-powered educational tools.\n",
    "\n",
    "\n",
    "Citation Granularity: While citations are provided, currently they are given at the resource level rather than specific passages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]\n",
    "\n",
    "[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/\n",
    "[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\n",
    "[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC-BY--NC--SA-4.0-lightgrey.svg\n",
    "\n",
    "```\n",
    "@misc{tharsistpsouza2024tamingllms,\n",
    "  author = {Tharsis T. P. Souza},\n",
    "  title = {Taming LLMs: A Practical Guide to LLM Pitfalls with Open Source Software},\n",
    "  year = {2024},\n",
    "  chapter = {Managing Input Data},\n",
    "  journal = {GitHub repository},\n",
    "  url = {https://github.com/souzatharsis/tamingLLMs)\n",
    "}\n",
    "```\n",
    "## References\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
