---
---

@misc{wei2022emergentabilitieslargelanguage,
      title={Emergent Abilities of Large Language Models}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.07682}, 
}

@misc{liang2024controllabletextgenerationlarge,
      title={Controllable Text Generation for Large Language Models: A Survey}, 
      author={Xun Liang and Hanyu Wang and Yezhaohui Wang and Shichao Song and Jiawei Yang and Simin Niu and Jie Hu and Dan Liu and Shunyu Yao and Feiyu Xiong and Zhiyu Li},
      year={2024},
      eprint={2408.12599},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.12599}, 
}

@misc{hf2024quantization,
      title={Quantization in Optimum},
      author={Hugging Face},
      year={2024s},
      howpublished={\url{https://huggingface.co/docs/optimum/en/concept_guides/quantization}},
      note={Accessed: 2024}
}


@misc{mistraltechnology2024,
      title={Mistral Technology and Pricing},
      author={Mistral AI},
      year={2024a},
      howpublished={\url{https://mistral.ai/technology/#pricing}},
      note={Accessed: 2024}
}


@misc{hf2024yearinreview,
      title={Open Source AI Year in Review 2024},
      author={Hugging Face},
      year={2024t},
      howpublished={\url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024}},
      note={Accessed: 2024}
}

@misc{penedo2024finewebdatasetsdecantingweb,
      title={The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale}, 
      author={Guilherme Penedo and Hynek Kydlíček and Loubna Ben allal and Anton Lozhkov and Margaret Mitchell and Colin Raffel and Leandro Von Werra and Thomas Wolf},
      year={2024},
      eprint={2406.17557},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.17557}, 
}

@misc{harvardlawreview2024nyt,
      title={NYT v. OpenAI: The Times's About-Face},
      author={Harvard Law Review},
      year={2024},
      howpublished={\url{https://harvardlawreview.org/blog/2024/04/nyt-v-openai-the-timess-about-face/}},
      note={Accessed: 2024}
}



@misc{outlines2024,
      title={Type-Safe Structured Output from LLMs},
      author={Outlines},
      year={2024},
      howpublished={\url{https://dottxt-ai.github.io/outlines/latest/}},
      note={Accessed: 2024}
}


@misc{tam2024letspeakfreelystudy,
      title={Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models}, 
      author={Zhi Rui Tam and Cheng-Kuang Wu and Yi-Lin Tsai and Chieh-Yen Lin and Hung-yi Lee and Yun-Nung Chen},
      year={2024},
      eprint={2408.02442},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.02442}, 
}

@misc{dottxt2024saywhatyoumean,
      title={Say What You Mean: Structured Output for LLMs},
      author={Dottxt},
      year={2024},
      howpublished={\url{https://blog.dottxt.co/say-what-you-mean.html}},
      note={Accessed: 2024}
}

@misc{aider2024codejson,
      title={Code in JSON: Structured Output for LLMs},
      author={Aider},
      year={2024},
      howpublished={\url{https://aider.chat/2024/08/14/code-in-json.html}},
      note={Accessed: 2024}
}

@misc{dottxt2024demos,
      title={Say What You Mean: Demos},
      author={Dottxt},
      year={2024},
      howpublished={\url{https://github.com/dottxt-ai/demos/tree/main/say-what-you-mean}},
      note={Accessed: 2024}
}

@misc{li2024leveraginglargelanguagemodels,
      title={Leveraging Large Language Models for NLG Evaluation: Advances and Challenges}, 
      author={Zhen Li and Xiaohan Xu and Tao Shen and Can Xu and Jia-Chen Gu and Yuxuan Lai and Chongyang Tao and Shuai Ma},
      year={2024},
      eprint={2401.07103},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.07103}, 
}

@misc{huggingface2024llmjudge,
      title={LLM as a Judge},
      author={Hugging Face},
      year={2024},
      howpublished={\url{https://huggingface.co/learn/cookbook/en/llm_judge}},
      note={Accessed: 2024}
}

@misc{nickel2024freedeliveryserviceepistemic,
      title={No Free Delivery Service: Epistemic limits of passive data collection in complex social systems}, 
      author={Maximilian Nickel},
      year={2024},
      eprint={2411.13653},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.13653}, 
}

@misc{judgearena2024,
      title={Judge Arena: Evaluating LLM Outputs with LLMs},
      author={Judge Arena},
      year={2024}, 
      howpublished={\url{https://judgearena.com/}},
      note={Accessed: 2024}
}

@misc{artificialanalysis2024providers,
      title={LLM Provider Leaderboards},
      author={Artificial Analysis},
      year={2024},
      howpublished={\url{https://artificialanalysis.ai/leaderboards/providers}},
      note={Accessed: 2024}
}


@misc{artificialanalysis2024methodology,
      title={Methodology},
      author={Artificial Analysis},
      year={2024},
      howpublished={\url{https://artificialanalysis.ai/methodology}},
      note={Accessed: December 22, 2024}
}


@misc{lighteval,
  author = {Fourrier, Clémentine and Habib, Nathan and Wolf, Thomas and Tunstall, Lewis},
  title = {LightEval: A lightweight framework for LLM evaluation},
  year = {2023},
  version = {0.5.0},
  url = {https://github.com/huggingface/lighteval}
}

@misc{artificialanalysis2024llmproviders,
      title={LLM Provider Leaderboards},
      author={Artificial Analysis},
      year={2024},
      howpublished={\url{https://artificialanalysis.ai/leaderboards/providers}},
      note={Accessed: 2024}
}


@misc{allal2024SmolLM2,
      title={SmolLM2 - with great data, comes great performance}, 
      author={Loubna Ben Allal and Anton Lozhkov and Elie Bakouch and Gabriel Martín Blázquez and Lewis Tunstall and Agustín Piqueres and Andres Marafioti and Cyril Zakka and Leandro von Werra and Thomas Wolf},
      year={2024},
}

@article{hui2024qwen2,
      title={Qwen2.5 - Coder Technical Report},
      author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
      journal={arXiv preprint arXiv:2409.12186},
      year={2024}
}

@article{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}

@misc{lighteval_tasks,
      title={Available Tasks - LightEval Wiki},
      author={Hugging Face},
      year={2024},
      howpublished={\url{https://github.com/huggingface/lighteval/wiki/Available-Tasks}},
      note={Accessed: 2024}
}

@misc{lighteval_metrics,
      title={Metric List - LightEval Wiki},
      author={Hugging Face},
      year={2024},
      howpublished={\url{https://github.com/huggingface/lighteval/wiki/Metric-List}},
      note={Accessed: 2024}
}

@misc{lighteval_server,
      title={Evaluate the model on a server or container - LightEval Wiki},
      author={Hugging Face},
      year={2024},
      howpublished={\url{https://github.com/huggingface/lighteval/wiki/Evaluate-the-model-on-a-server-or-container}},
      note={Accessed: 2024}
}



@misc{gpt2docs,
      title={GPT-2 Documentation - Hugging Face Transformers},
      author={Hugging Face},
      year={2024},
      howpublished={\url{https://huggingface.co/docs/transformers/model_doc/gpt2}},
      note={Accessed: 2024}
}






@misc{qwen_openrouter_usage,
      title={Qwen Usage on OpenRouter},
      author={{OpenRouter}},
      year={2024},
      howpublished={\url{https://x.com/OpenRouterAI/status/1864549260089327936}},
      note={Accessed: 12/06/2024}
}

@misc{hf_num_models,
      title={Number of Models on Hugging Face},
      author={{Hugging Face}},
      year={2024},
      howpublished={\url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024?day=4}},
      note={Accessed: 12/06/2024}
}

@misc{meta_llama_models,
      title={Meta Llama Models on Hugging Face},
      author={{Meta AI}},
      year={2024},
      howpublished={\url{https://huggingface.co/meta-llama}},
      note={Accessed: 2024}
}

@misc{promptfoo,
      title={PromptFoo - Open-source prompt engineering toolkit},
      author={{PromptFoo}},
      year={2024},
      howpublished={\url{https://www.promptfoo.dev/}},
      note={Accessed: 12/06/2024}
}

@misc{llama_cpp_grammars,
      title={Llama.cpp Grammars Documentation},
      author={Ggerganov},
      year={2024},
      howpublished={\url{https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md}},
      note={Accessed: 2024}
}

@misc{backus_naur_form,
      title={Backus Naur form},
      author={{Wikipedia contributors}},
      year={2024},
      howpublished={\url{https://en.wiktionary.org/wiki/Backus-Naur_form}},
      note={Accessed: 2024}
}

@inproceedings{10.1145/3613905.3650756,
author = {Liu, Michael Xieyang and Liu, Frederick and Fiannaca, Alexander J. and Koo, Terry and Dixon, Lucas and Terry, Michael and Cai, Carrie J.},
title = {"We Need Structured Output": Towards User-centered Constraints on Large Language Model Output},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650756},
doi = {10.1145/3613905.3650756},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {10},
numpages = {9},
keywords = {Constrained generation, Large language models, Survey},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{long2024llms,
  title={LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs},
  author={Long, Do Xuan and Ngoc, Hai Nguyen and Sim, Tiviatis and Dao, Hieu and Joty, Shafiq and Kawaguchi, Kenji and Chen, Nancy F and Kan, Min-Yen},
  journal={arXiv preprint arXiv:2408.08656},
  year={2024}
}

@misc{langchain_text_splitters,
      title={Text Splitters - LangChain Documentation},
      author={{LangChain}},
      year={2024},
      howpublished={\url{https://python.langchain.com/docs/how_to/#text-splitters}},
      note={Accessed: 12/07/2024}
}


@misc{holtzman2020curiouscaseneuraltext,
      title={The Curious Case of Neural Text Degeneration}, 
      author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
      year={2020},
      eprint={1904.09751},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09751}, 
}

@misc{white2024livebenchchallengingcontaminationfreellm,
      title={LiveBench: A Challenging, Contamination-Free LLM Benchmark}, 
      author={Colin White and Samuel Dooley and Manley Roberts and Arka Pal and Ben Feuer and Siddhartha Jain and Ravid Shwartz-Ziv and Neel Jain and Khalid Saifullah and Siddartha Naidu and Chinmay Hegde and Yann LeCun and Tom Goldstein and Willie Neiswanger and Micah Goldblum},
      year={2024},
      eprint={2406.19314},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19314}, 
}

@misc{wang2019gluemultitaskbenchmarkanalysis,
      title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding}, 
      author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2019},
      eprint={1804.07461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1804.07461}, 
}

@article{nangia2019superglue,
title = "SuperGLUE: A stickier benchmark for general-purpose language understanding systems",
year = "2019",
author = "Alex Wang and Yada Pruksachatkun and Nikita Nangia and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Bowman, {Samuel R.}",
language = "English (US)",
volume = "32",
journal = "Advances in Neural Information Processing Systems",
issn = "1049-5258",
publisher = "Neural information processing systems foundation",
}

@misc{srivastava2023imitationgamequantifyingextrapolating,
      title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models}, 
      author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmüller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and César Ferri Ramírez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D. Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Moseguí González and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A. Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martínez-Plumed and Francesca Happé and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germán Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang and Gonzalo Jaimovitch-López and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Shevlin and Hinrich Schütze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fernández Fisac and James B. Simon and James Koppel and James Zheng and James Zou and Jan Kocoń and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and Jörg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh D. Dhole and Kevin Gimpel and Kevin Omondi and Kory Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros Colón and Luke Metz and Lütfi Kerem Şenel and Maarten Bosma and Maarten Sap and Maartje ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramírez Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L. Leavitt and Matthias Hagen and Mátyás Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael A. Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Michał Swędrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan A. Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Miłkowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Raphaël Millière and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan LeBras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Ruslan Salakhutdinov and Ryan Chi and Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel S. Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima and Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven T. Piantadosi and Stuart M. Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsu Hashimoto and Te-Lin Wu and Théo Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Ramasesh and Vinay Uday Prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
      year={2023},
      eprint={2206.04615},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.04615}, 
}

@book{kamath2024large,
  title={Large Language Models: A Deep Dive: Bridging Theory and Practice},
  author={Kamath, U. and Keenan, K. and Somers, G. and Sorenson, S.},
  isbn={9783031656477},
  url={https://books.google.com.br/books?id=kDobEQAAQBAJ},
  year={2024},
  publisher={Springer Nature Switzerland}
}

@misc{2021truthfulqa,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.07958}, 
}

@misc{liang2023holisticevaluationlanguagemodels,
      title={Holistic Evaluation of Language Models}, 
      author={Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher Ré and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda},
      year={2023},
      eprint={2211.09110},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2211.09110}, 
}

@misc{hendrycks2021measuringmassivemultitasklanguage,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@misc{chen2021evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.03374}, 
}

@misc{chiang2024chatbotarenaopenplatform,
      title={Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference}, 
      author={Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},
      year={2024},
      eprint={2403.04132},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2403.04132}, 
}

@misc{openllmleaderboard2024,
      title={Open LLM Leaderboard},
      author={Hugging Face},
      year={2024},
      howpublished={Hugging Face Spaces},
      url={https://huggingface.co/spaces/open-llm-leaderboard/blog},
}

@misc{dubois2024lengthcontrolledalpacaevalsimpleway,
      title={Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators}, 
      author={Yann Dubois and Balázs Galambosi and Percy Liang and Tatsunori B. Hashimoto},
      year={2024},
      eprint={2404.04475},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.04475}, 
}

@misc{zheng2023judgingllmasajudgemtbenchchatbot,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.05685}, 
}

@misc{arcprize2024,
      title={Abstraction and Reasoning Challenge},
      author={Francois Chollet},
      year={2024},
      howpublished={ARC Prize Website},
      url={https://arcprize.org/},
}

@misc{arcprizeresults2024,
      title={ARC Prize 2024 Results},
      author={Francois Chollet},
      year={12/08/2024},
      howpublished={ARC Prize Website},
      url={https://arcprize.org/2024-results},
}

@book{build-llms-from-scratch-book,
  author       = {Sebastian Raschka},
  title        = {Build A Large Language Model (From Scratch)},
  publisher    = {Manning},
  year         = {2024},
  isbn         = {978-1633437166},
  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
  github       = {https://github.com/rasbt/LLMs-from-scratch}
}

@misc{zebralogic2024,
    title={ZebraLogic: Benchmarking the Logical Reasoning Ability of Language Models},
    author={Bill Yuchen Lin and Ronan Le Bras and Yejin Choi},
    url={https://huggingface.co/spaces/allenai/ZebraLogic},
    year={2024}
}

@article{brailsford1999constraint,
title = {Constraint satisfaction problems: Algorithms and applications},
journal = {European Journal of Operational Research},
volume = {119},
number = {3},
pages = {557-581},
year = {1999},
issn = {0377-2217},
doi = {https://doi.org/10.1016/S0377-2217(98)00364-6},
url = {https://www.sciencedirect.com/science/article/pii/S0377221798003646},
author = {Sally C. Brailsford and Chris N. Potts and Barbara M. Smith}
}

@misc{vivien2024regex,
title={Fast, High-Fidelity LLM Decoding with Regex Constraints},
url={https://vivien000.github.io/blog/journal/llm-decoding-with-regex-constraints.html},
journal={Unsupervised Thoughts (blog)},
author={Tran-Thien, Vivien},
year={2024}
}

@misc{willard2023efficientguidedgenerationlarge,
      title={Efficient Guided Generation for Large Language Models}, 
      author={Brandon T. Willard and Rémi Louf},
      year={2023},
      eprint={2307.09702},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09702}, 
}

@misc{smollm2024model,
    title={SmolLM2-360M-Instruct},
    author={Hugging Face SmolLM2-360M-Instruct},
    year={2024},
    url={https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct},
    note={360M parameter instruction-tuned language model, distilled for efficient deployment}
}

@misc{promptfoo2024,
    title={promptfoo: LLM Testing and Evaluation Framework},
    author={promptfoo},
    year={2024},
    url={https://www.promptfoo.dev/},
    note={Open source framework for testing and evaluating LLM prompts}
}


@misc{vidgen2024introducingv05aisafety,
      title={Introducing v0.5 of the AI Safety Benchmark from MLCommons}, 
      author={Bertie Vidgen and Adarsh Agrawal and Ahmed M. Ahmed and Victor Akinwande and Namir Al-Nuaimi and Najla Alfaraj and Elie Alhajjar and Lora Aroyo and Trupti Bavalatti and Max Bartolo and Borhane Blili-Hamelin and Kurt Bollacker and Rishi Bomassani and Marisa Ferrara Boston and Siméon Campos and Kal Chakra and Canyu Chen and Cody Coleman and Zacharie Delpierre Coudert and Leon Derczynski and Debojyoti Dutta and Ian Eisenberg and James Ezick and Heather Frase and Brian Fuller and Ram Gandikota and Agasthya Gangavarapu and Ananya Gangavarapu and James Gealy and Rajat Ghosh and James Goel and Usman Gohar and Sujata Goswami and Scott A. Hale and Wiebke Hutiri and Joseph Marvin Imperial and Surgan Jandial and Nick Judd and Felix Juefei-Xu and Foutse Khomh and Bhavya Kailkhura and Hannah Rose Kirk and Kevin Klyman and Chris Knotz and Michael Kuchnik and Shachi H. Kumar and Srijan Kumar and Chris Lengerich and Bo Li and Zeyi Liao and Eileen Peters Long and Victor Lu and Sarah Luger and Yifan Mai and Priyanka Mary Mammen and Kelvin Manyeki and Sean McGregor and Virendra Mehta and Shafee Mohammed and Emanuel Moss and Lama Nachman and Dinesh Jinenhally Naganna and Amin Nikanjam and Besmira Nushi and Luis Oala and Iftach Orr and Alicia Parrish and Cigdem Patlak and William Pietri and Forough Poursabzi-Sangdeh and Eleonora Presani and Fabrizio Puletti and Paul Röttger and Saurav Sahay and Tim Santos and Nino Scherrer and Alice Schoenauer Sebag and Patrick Schramowski and Abolfazl Shahbazi and Vin Sharma and Xudong Shen and Vamsi Sistla and Leonard Tang and Davide Testuggine and Vithursan Thangarasa and Elizabeth Anne Watkins and Rebecca Weiss and Chris Welty and Tyler Wilbers and Adina Williams and Carole-Jean Wu and Poonam Yadav and Xianjun Yang and Yi Zeng and Wenhui Zhang and Fedor Zhdanov and Jiacheng Zhu and Percy Liang and Peter Mattson and Joaquin Vanschoren},
      year={2024},
      eprint={2404.12241},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.12241}, 
}

@misc{kim2024evaluatinglanguagemodelssynthetic,
      title={Evaluating Language Models as Synthetic Data Generators}, 
      author={Seungone Kim and Juyoung Suk and Xiang Yue and Vijay Viswanathan and Seongyun Lee and Yizhong Wang and Kiril Gashteovski and Carolin Lawrence and Sean Welleck and Graham Neubig},
      year={2024},
      eprint={2412.03679},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03679}, 
}

@misc{wu2024metarewardinglanguagemodelsselfimproving,
      title={Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge}, 
      author={Tianhao Wu and Weizhe Yuan and Olga Golovneva and Jing Xu and Yuandong Tian and Jiantao Jiao and Jason Weston and Sainbayar Sukhbaatar},
      year={2024},
      eprint={2407.19594},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.19594}, 
}

@misc{smollm2024,
    title={SmoLLM: A Small Language Model Distilled from a Larger Language Model for Task-specific Applications},
    author={Hugging Face SmolLM2},
    year={2024},
    url={https://huggingface.co/blog/smollm},
    note={Blog post describing techniques for distilling smaller, task-specific language models}
}

@article{Yin2024SelfAugmentedPO,
  title={Self-Augmented Preference Optimization: Off-Policy Paradigms for Language Model Alignment},
  author={Yueqin Yin and Zhendong Wang and Yujia Xie and Weizhu Chen and Mingyuan Zhou},
  journal={ArXiv},
  year={2024},
  volume={abs/2405.20830},
  url={https://api.semanticscholar.org/CorpusID:270199610}
}


@misc{bai2022constitutionalaiharmlessnessai,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.08073}, 
}

@misc{dong2024selfboostinglargelanguagemodels,
      title={Self-Boosting Large Language Models with Synthetic Preference Data}, 
      author={Qingxiu Dong and Li Dong and Xingxing Zhang and Zhifang Sui and Furu Wei},
      year={2024},
      eprint={2410.06961},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.06961}, 
}

@misc{askell2024alignmentfaking,
      title={Alignment Faking in Large Language Models}, 
      author={Amanda Askell and Jan Brauner and Adrian Colyer and Benjamin Cullen and David Duvenaud and Richard Ngo and Azalia Mirhoseini and Catherine Olsson and Sam Ringer and Liam Skirvin and Jess Smith and Dawn Song and William Saunders and Steinhardt, Jacob},
      year={2024a},
      publisher={Anthropic},
      url={https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf}
}

@misc{askell2024alignmentfakingreviews,
      title={Alignment Faking in Large Language Models: Reviews}, 
      author={Amanda Askell and Jan Brauner and Adrian Colyer and Benjamin Cullen and David Duvenaud and Richard Ngo and Azalia Mirhoseini and Catherine Olsson and Sam Ringer and Liam Skirvin and Jess Smith and Dawn Song and William Saunders and Steinhardt, Jacob},
      year={2024b},
      publisher={Anthropic},
      url={https://assets.anthropic.com/m/24c8d0a3a7d0a1f1/original/Alignment-Faking-in-Large-Language-Models-reviews.pdf}
}

@misc{ggerganov2023llamacppdiscussion,
    title={Quantization of LLaMA models - Discussion},
    author={Georgi Gerganov and others},
    year={2023},
    howpublished={GitHub Discussion},
    url={https://github.com/ggerganov/llama.cpp/discussions/205},
    note={Discussion thread about quantization techniques and tradeoffs in llama.cpp}
}


@misc{lmstudio2024,
    title={LM Studio - Discover, Download, and Run Local LLMs},
    author={{LM Studio}},
    year={2024},
    howpublished={Website},
    url={https://lmstudio.ai/},
    note={Desktop application for discovering, downloading and running local language models}
}


@misc{mozilla2024llamafile,
    title={llamafile: Distribute and run LLMs with a single file},
    author={{Mozilla Ocho}},
    year={2024},
    howpublished={GitHub Repository}, 
    url={https://github.com/Mozilla-Ocho/llamafile},
    note={Tool for packaging and distributing LLMs as self-contained executables}
}


@misc{huggingface2024llamafilemodels,
    title={Llamafile Models on Hugging Face},
    author={{Hugging Face}},
    year={2024x},
    howpublished={Online Repository},
    url={https://huggingface.co/models?library=llamafile},
    note={Collection of models compatible with Mozilla's llamafile format}
}


@misc{huggingface2024chattemplating,
    title={Chat Templating Documentation},
    author={{Hugging Face}},
    year={2024y},
    howpublished={Online Documentation},
    url={https://huggingface.co/docs/transformers/main/en/chat_templating},
    note={Documentation on chat templates and formatting for language models}
}

@misc{betlen2024llamacpppython,
    title={llama-cpp-python},
    author={Andrei Betlen and contributors},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/abetlen/llama-cpp-python},
    note={Python bindings for llama.cpp library enabling high-performance inference of LLaMA models}
}

@misc{meta2024llama2chat70b,
    title={Llama-2-70b-chat-hf},
    author={{Meta AI}},
    year={2024c},
    howpublished={Hugging Face Model},
    url={https://huggingface.co/meta-llama/Llama-2-70b-chat-hf},
    note={70 billion parameter chat model from Meta's Llama 2 family}
}


@misc{deshpande2024glidergradingllminteractions,
      title={GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking}, 
      author={Darshan Deshpande and Selvan Sunitha Ravi and Sky CH-Wang and Bartosz Mielczarek and Anand Kannappan and Rebecca Qian},
      year={2024},
      eprint={2412.14140},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.14140}, 
}

@misc{unsloth2024llama3,
    title={Llama-3.3-70B-Instruct-GGUF},
    author={{Unsloth}},
    year={2024},
    howpublished={Hugging Face Model},
    url={https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF},
    note={GGUF quantized version of Meta's Llama 3.3 70B instruction-tuned model}
}


@misc{nvidia2024logitsprocessorzoo,
    title={Logits Processor Zoo},
    author={{NVIDIA}},
    year={2024a},
    howpublished={GitHub Repository},
    url={https://github.com/NVIDIA/logits-processor-zoo},
    note={Collection of logits processors for controlling language model generation}
}


@misc{guidance2024repo,
    title={Guidance: Language Model Programming},
    author={{Guidance AI}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/guidance-ai/guidance},
    note={Framework for programming language models with structured templating and control flow}
}


@misc{alnajjar2024toxigen,
    title={ToxiGen Dataset},
    author={Alnajjar, Khalid and others},
    year={2024},
    howpublished={Papers with Code Dataset},
    url={https://paperswithcode.com/dataset/toxigen},
    note={Dataset for evaluating and mitigating toxic language generation in language models}
}

@misc{sarmah2024choosethresholdevaluationmetric,
      title={How to Choose a Threshold for an Evaluation Metric for Large Language Models}, 
      author={Bhaskarjit Sarmah and Mingshu Li and Jingrao Lyu and Sebastian Frank and Nathalia Castellanos and Stefano Pasquali and Dhagash Mehta},
      year={2024},
      eprint={2412.12148},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2412.12148}, 
}

@misc{salesforce2024wikitext,
    title={WikiText Dataset},
    author={{Salesforce}},
    year={2024},
    howpublished={Hugging Face Dataset},
    url={https://huggingface.co/datasets/Salesforce/wikitext},
    note={Large-scale dataset derived from verified Good and Featured articles on Wikipedia}
}

@misc{wang20241bitaiinfra11,
      title={1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs}, 
      author={Jinheng Wang and Hansong Zhou and Ting Song and Shaoguang Mao and Shuming Ma and Hongyu Wang and Yan Xia and Furu Wei},
      year={2024},
      eprint={2410.16144},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.16144}, 
}

@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.11401}, 
}

@misc{deepseek2024v3,
    title={DeepSeek-V3 Technical Report},
    author={DeepSeek},
    year={2024},
    howpublished={Technical Report},
    url={https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf}
}

@misc{lee2024longcontextlanguagemodelssubsume,
      title={Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?}, 
      author={Jinhyuk Lee and Anthony Chen and Zhuyun Dai and Dheeru Dua and Devendra Singh Sachan and Michael Boratko and Yi Luan and Sébastien M. R. Arnold and Vincent Perot and Siddharth Dalmia and Hexiang Hu and Xudong Lin and Panupong Pasupat and Aida Amini and Jeremy R. Cole and Sebastian Riedel and Iftekhar Naim and Ming-Wei Chang and Kelvin Guu},
      year={2024},
      eprint={2406.13121},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.13121}, 
}


@misc{merrill2024,
    title={CHIEF INVESTMENT OFFICER CAPITAL MARKET OUTLOOK},
    author={{Merrill Lynch}},
    year={2024},
    howpublished={CIO Weekly Letter},
    url={https://olui2.fs.ml.com/publish/content/application/pdf/gwmol/me-cio-weekly-letter.pdf}
}


@misc{a16z2024llmflation,
    title={LLMflation: Understanding and Mitigating LLM Inference Cost},
    author={{Andreessen Horowitz}},
    year={2024},
    howpublished={Blog Post},
    url={https://a16z.com/llmflation-llm-inference-cost/},
    note={Analysis of LLM inference costs and strategies for optimization}
}


@misc{huggingface2024quantization,
    title={GGUF Quantization Types},
    author={{Hugging Face}},
    year={2024w},
    howpublished={Online Documentation},
    url={https://huggingface.co/docs/hub/gguf#quantization-types},
    note={Documentation on different quantization types available for GGUF models}
}


@misc{ggerganov2024llamacppgrammars,
    title={llama.cpp Grammars Documentation},
    author={Georgi Gerganov and contributors},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md},
    note={Documentation on using grammars for constrained text generation in llama.cpp}
}


@misc{langchain2024outlines,
    title={Outlines Integration Documentation},
    author={LangChain},
    year={2024b},
    howpublished={Online Documentation},
    url={https://python.langchain.com/docs/integrations/chat/outlines/},
    note={Documentation on integrating Outlines library with LangChain for structured generation}
}


@misc{ggerganov2024llamacpp,
    title={llama.cpp},
    author={Georgi Gerganov and contributors},
    year={2024a},
    howpublished={GitHub Repository},
    url={https://github.com/ggerganov/llama.cpp},
    note={High-performance inference of LLaMA models in pure C/C++}
}



@misc{ibm2024ggufversusggml,
    title={GGUF vs GGML: What's the Difference?},
    author={{IBM Think}},
    year={2024},
    publisher={IBM},
    url={https://www.ibm.com/think/topics/gguf-versus-ggml},
    note={Comparison of GGUF and GGML model formats}
}

@misc{huggingface2024ggufmodels,
    title={GGUF Models on Hugging Face},
    author={{Hugging Face}},
    year={2024x},
    howpublished={Online Repository},
    url={https://huggingface.co/models?search=gguf},
    note={Collection of models in GGUF format for efficient local inference}
}

@misc{ggerganov2024ggufspec,
    title={GGUF File Format Specification},
    author={Georgi Gerganov and contributors},
    year={2024b},
    howpublished={GitHub Repository},
    url={https://github.com/ggerganov/ggml/blob/master/docs/gguf.md},
    note={Technical specification of the GGUF file format for efficient model storage and inference}
}





@misc{singh2024globalmmluunderstandingaddressing,
      title={Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation}, 
      author={Shivalika Singh and Angelika Romanou and Clémentine Fourrier and David I. Adelani and Jian Gang Ngui and Daniel Vila-Suero and Peerat Limkonchotiwat and Kelly Marchisio and Wei Qi Leong and Yosephine Susanto and Raymond Ng and Shayne Longpre and Wei-Yin Ko and Madeline Smith and Antoine Bosselut and Alice Oh and Andre F. T. Martins and Leshem Choshen and Daphne Ippolito and Enzo Ferrante and Marzieh Fadaee and Beyza Ermis and Sara Hooker},
      year={2024},
      eprint={2412.03304},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03304}, 
}



@book{huyen2024aiengineering,
    title={AI Engineering},
    author={Huyen, Chip},
    year={2024},
    publisher={O'Reilly Media, Inc.},
    month={December},
    isbn={9781098129095},
    url={https://www.oreilly.com/library/view/ai-engineering/9781098129095/}
}

@misc{feng2024analyzingunderstandinglimitationsdpo,
      title={Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective}, 
      author={Duanyu Feng and Bowen Qin and Chen Huang and Zheng Zhang and Wenqiang Lei},
      year={2024},
      eprint={2404.04626},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.04626}, 
}

@misc{hou2024doesrlhfscaleexploring,
      title={Does RLHF Scale? Exploring the Impacts From Data, Model, and Method}, 
      author={Zhenyu Hou and Pengfan Du and Yilin Niu and Zhengxiao Du and Aohan Zeng and Xiao Liu and Minlie Huang and Hongning Wang and Jie Tang and Yuxiao Dong},
      year={2024},
      eprint={2412.06000},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.06000}, 
}

@misc{szep2024practicalguidefinetuninglanguage,
      title={A Practical Guide to Fine-tuning Language Models with Limited Data}, 
      author={Márton Szép and Daniel Rueckert and Rüdiger von Eisenhart-Rothe and Florian Hinterwimmer},
      year={2024},
      eprint={2411.09539},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.09539}, 
}

@misc{kazdan2024collapsethriveperilspromises,
      title={Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World}, 
      author={Joshua Kazdan and Rylan Schaeffer and Apratim Dey and Matthias Gerstgrasser and Rafael Rafailov and David L. Donoho and Sanmi Koyejo},
      year={2024},
      eprint={2410.16713},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.16713}, 
}

@misc{mlcommons2024lead,
    title={MLCommons AI Illuminate Benchmarks},
    author={MLCommons},
    year={2024},
    url={https://ailuminate.mlcommons.org/benchmarks/},
    note={A collection of standardized benchmarks for evaluating AI systems}
}


@misc{ultrafeedback2024,
    title={UltraFeedback Binarized Dataset},
    author={Hugging Face H4},
    year={2024a},
    url={https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized},
    note={A dataset of binary preference data for training language models}
}


@misc{ultrafeedback2024z,
    title={UltraFeedback Binarized Dataset},
    author={Hugging Face H4},
    year={2024z},
    url={https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized},
    note={A dataset of binary preference data for training language models}
}

@misc{huggingfaceh42024,
    title={Hugging Face H4},
    author={Hugging Face H4},
    year={2024b},
    url={https://huggingface.co/HuggingFaceH4},
    note={Hugging Face H4}
}

@misc{evalstamingllms2024,
    title={TamingLLMs: A Framework for Evaluating and Aligning Language Models},
    chapter={The Evals Gap},
    author={Tharsis T. P. Souza},
    year={2024},
    url={https://www.souzatharsis.com/tamingLLMs/notebooks/evals.html}
}

@misc{evalstamingllms2024b,
    title={TamingLLMs: A Framework for Evaluating and Aligning Language Models},
    chapter={Wrestling with Structured Output},
    author={Tharsis T. P. Souza},
    year={2024},
    url={https://www.souzatharsis.com/tamingLLMs/notebooks/structured_output.html}
}


@misc{huang2022largelanguagemodelsselfimprove,
      title={Large Language Models Can Self-Improve}, 
      author={Jiaxin Huang and Shixiang Shane Gu and Le Hou and Yuexin Wu and Xuezhi Wang and Hongkun Yu and Jiawei Han},
      year={2022},
      eprint={2210.11610},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.11610}, 
}


@misc{long2024llmsdrivensyntheticdatageneration,
      title={On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey}, 
      author={Lin Long and Rui Wang and Ruixuan Xiao and Junbo Zhao and Xiao Ding and Gang Chen and Haobo Wang},
      year={2024},
      eprint={2406.15126},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.15126}, 
}

@misc{hao2024syntheticdataaichallenges,
      title={Synthetic Data in AI: Challenges, Applications, and Ethical Implications}, 
      author={Shuang Hao and Wenfeng Han and Tao Jiang and Yiping Li and Haonan Wu and Chunlin Zhong and Zhangjun Zhou and He Tang},
      year={2024},
      eprint={2401.01629},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.01629}, 
}

@misc{chen2024humansllmsjudgestudy,
      title={Humans or LLMs as the Judge? A Study on Judgement Biases}, 
      author={Guiming Hardy Chen and Shunian Chen and Ziche Liu and Feng Jiang and Benyou Wang},
      year={2024},
      eprint={2402.10669},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10669}, 
}

@misc{meta-llama2024,
    title={Meta-Llama},
    author={Meta},
    year={2024},
    url={https://huggingface.co/meta-llama},
    note={Meta-Llama}
}

@misc{qwen2024,
    title={Qwen},
    author={Qwen},
    year={2024},
    url={https://huggingface.co/Qwen},
    note={Qwen}
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Meta AI},
      year={2024c},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{hf2024scalingtesttime,
    title={Scaling Test Time Compute},
    author={Hugging Face},
    year={2024v},
    url={https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
    note={Accessed: 2024}
}

@misc{hf2024ultrachat200k,
    title={UltraChat-200K Dataset},
    author={Hugging Face},
    year={2024u},
    url={https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k},
    note={Accessed: 2024}
}


@misc{zhao2024loraland310finetuned,
      title={LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report}, 
      author={Justin Zhao and Timothy Wang and Wael Abid and Geoffrey Angus and Arnav Garg and Jeffery Kinnison and Alex Sherstinsky and Piero Molino and Travis Addair and Devvret Rishi},
      year={2024},
      eprint={2405.00732},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.00732}, 
}

@misc{qwen2024moe,
    title={Qwen-MoE: Serving Large Language Models with Mixture of Experts},
    author={Qwen Team},
    year={2024},
    url={https://qwenlm.github.io/blog/qwen-moe/},
    note={Accessed: 2024}
}



@misc{qwen25instruct2024,
    title={Qwen2.5-1.5B-Instruct},
    author={Qwen},
    year={2024b},
    url={https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct},
    note={Accessed: December 22, 2024}
}




@misc{qwen2024qwen25technicalreport,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2024},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115}, 
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{zephyr2024,
    title={Zephyr},
    author={Hugging Face},
    year={2024},
    url={https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha},
    note={Zephyr}
}

@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}

@misc{hong2024orpomonolithicpreferenceoptimization,
      title={ORPO: Monolithic Preference Optimization without Reference Model}, 
      author={Jiwoo Hong and Noah Lee and James Thorne},
      year={2024},
      eprint={2403.07691},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.07691}, 
}


@misc{rafailov2024directpreferenceoptimizationlanguage,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}

@techreport{ukgov2024airegulation24,
      title={AI Regulation: A Pro-Innovation Approach}, 
      author={{UK Government}},
      year={2024},
      institution={Department for Science, Innovation and Technology},
      type={White Paper},
      url={https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper},
}


@inproceedings{10.1145/3589334.3645481,
author = {Zhou, Yujia and Liu, Zheng and Jin, Jiajie and Nie, Jian-Yun and Dou, Zhicheng},
title = {Metacognitive Retrieval-Augmented Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645481},
doi = {10.1145/3589334.3645481},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1453-1463},
numpages = {11},
keywords = {llms, metacognition, retrieval-augmented generation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@misc{tan2024htmlraghtmlbetterplain,
      title={HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems}, 
      author={Jiejun Tan and Zhicheng Dou and Wen Wang and Mang Wang and Weipeng Chen and Ji-Rong Wen},
      year={2024},
      eprint={2411.02959},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2411.02959}, 
}

@misc{anthropic2024contextualretrieval,
      title={Introducing Contextual Retrieval}, 
      author={{Anthropic}},
      year={2024a},
      month={09},
      url={https://www.anthropic.com/news/contextual-retrieval}
}


@article{zhou2024larger,
author = {Zhou, Lexin and Schellaert, Wout and Plumed, Fernando and Moros-Daval, Yael and Ferri, Cesar and Hernández-Orallo, Jose},
year = {2024},
month = {09},
pages = {61-68},
title = {Larger and more instructable language models become less reliable},
volume = {634},
journal = {Nature},
doi = {10.1038/s41586-024-07930-y}
}

@inproceedings{amayuelas-etal-2024-knowledge,
    title = "Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models",
    author = "Amayuelas, Alfonso  and
      Wong, Kyle  and
      Pan, Liangming  and
      Chen, Wenhu  and
      Wang, William Yang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.383",
    doi = "10.18653/v1/2024.findings-acl.383",
    pages = "6416--6432",

}

@inproceedings{
kotha2024understanding,
title={Understanding Catastrophic Forgetting in Language Models via Implicit Inference},
author={Suhas Kotha and Jacob Mitchell Springer and Aditi Raghunathan},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=VrHiF2hsrm}
}



@inproceedings{ni-etal-2024-llms,
    title = "When Do {LLM}s Need Retrieval Augmentation? Mitigating {LLM}s{'} Overconfidence Helps Retrieval Augmentation",
    author = "Ni, Shiyu  and
      Bi, Keping  and
      Guo, Jiafeng  and
      Cheng, Xueqi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.675",
    doi = "10.18653/v1/2024.findings-acl.675",
    pages = "11375--11388",
}

@misc{meta2024llamaguard,
      title={LlamaGuard: LLM-based Input-Output Safeguard for Human-AI Conversations}, 
      author={Meta-AI},
      year={2024},
      howpublished={Meta AI Research Publications},
      url={https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/},
}



@misc{touvron2023llama2openfoundation,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}

@misc{bai2022traininghelpfulharmlessassistant,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.05862}, 
}

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}

@misc{xu2024dposuperiorppollm,
      title={Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study}, 
      author={Shusheng Xu and Wei Fu and Jiaxuan Gao and Wenjie Ye and Weilin Liu and Zhiyu Mei and Guangju Wang and Chao Yu and Yi Wu},
      year={2024},
      eprint={2404.10719},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.10719}, 
}

@misc{huggingface2024rlhf,
    title={RLHF},
    author={Hugging Face},
    year={2024c},
    url={https://huggingface.co/blog/rlhf},
    note={RLHF}
}

@misc{schulman2017proximalpolicyoptimizationalgorithms,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@misc{neurips2023awards,
    title={Announcing the NeurIPS 2023 Paper Awards},
    author={NeurIPS Blog},
    year={2023},
    url={https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/},
    note={NeurIPS 2023 Awards}
}


@techreport{finra2024llmguidance24,
      title={Artificial Intelligence, Including Large Language Models and Generative AI}, 
      author={{Financial Industry Regulatory Authority}},
      year={2024},
      institution={FINRA},
      type={Regulatory Notice},
      number={24-09},
      url={https://www.finra.org/rules-guidance/notices/24-09},
}



@misc{huggingface2024trl,
    title={TRL},
    author={Hugging Face},
    year={2024d},
    url={https://huggingface.co/docs/trl/en/index},
    note={TRL}
}

@misc{vidgen2024simplesafetyteststestsuiteidentifying,
      title={SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models}, 
      author={Bertie Vidgen and Nino Scherrer and Hannah Rose Kirk and Rebecca Qian and Anand Kannappan and Scott A. Hale and Paul Röttger},
      year={2024},
      eprint={2311.08370},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08370}, 
}


@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@inproceedings{hartvigsen-etal-2022-toxigen,
    title = "{T}oxi{G}en: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection",
    author = "Hartvigsen, Thomas  and
      Gabriel, Saadia  and
      Palangi, Hamid  and
      Sap, Maarten  and
      Ray, Dipankar  and
      Kamar, Ece",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.234",
    doi = "10.18653/v1/2022.acl-long.234",
    pages = "3309--3326",
}






@article{Huang_2024,
   title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
   ISSN={1558-2868},
   url={http://dx.doi.org/10.1145/3703155},
   DOI={10.1145/3703155},
   journal={ACM Transactions on Information Systems},
   publisher={Association for Computing Machinery (ACM)},
   author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
   year={2024},
   month=nov }

@misc{bowen2024datapoisoningllmsjailbreaktuning,
      title={Data Poisoning in LLMs: Jailbreak-Tuning and Scaling Laws}, 
      author={Dillon Bowen and Brendan Murphy and Will Cai and David Khachaturov and Adam Gleave and Kellin Pelrine},
      year={2024},
      eprint={2408.02946},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2408.02946}, 
}

@misc{gallegos2024biasfairnesslargelanguage,
      title={Bias and Fairness in Large Language Models: A Survey}, 
      author={Isabel O. Gallegos and Ryan A. Rossi and Joe Barrow and Md Mehrab Tanjim and Sungchul Kim and Franck Dernoncourt and Tong Yu and Ruiyi Zhang and Nesreen K. Ahmed},
      year={2024},
      eprint={2309.00770},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.00770}, 
}

@misc{zhang2024ghostpastidentifyingresolving,
      title={"Ghost of the past": identifying and resolving privacy leakage from LLM's memory through proactive user interaction}, 
      author={Shuning Zhang and Lyumanshan Ye and Xin Yi and Jingyu Tang and Bo Shui and Haobin Xing and Pengfei Liu and Hewu Li},
      year={2024},
      eprint={2410.14931},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2410.14931}, 
}

@misc{benjamin2024systematicallyanalyzingpromptinjection,
      title={Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures}, 
      author={Victoria Benjamin and Emily Braca and Israel Carter and Hafsa Kanchwala and Nava Khojasteh and Charly Landow and Yi Luo and Caroline Ma and Anna Magarelli and Rachel Mirin and Avery Moyer and Kayla Simpson and Amelia Skawinski and Thomas Heverin},
      year={2024},
      eprint={2410.23308},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.23308}, 
}

@article{bengio2024managingextremeaiaidrapidprogress,
author = {Yoshua Bengio  and Geoffrey Hinton  and Andrew Yao  and Dawn Song  and Pieter Abbeel  and Trevor Darrell  and Yuval Noah Harari  and Ya-Qin Zhang  and Lan Xue  and Shai Shalev-Shwartz  and Gillian Hadfield  and Jeff Clune  and Tegan Maharaj  and Frank Hutter  and Atılım Güneş Baydin  and Sheila McIlraith  and Qiqi Gao  and Ashwin Acharya  and David Krueger  and Anca Dragan  and Philip Torr  and Stuart Russell  and Daniel Kahneman  and Jan Brauner  and Sören Mindermann },
title = {Managing extreme AI risks amid rapid progress},
journal = {Science},
volume = {384},
number = {6698},
pages = {842-845},
year = {2024},
doi = {10.1126/science.adn0117},
URL = {https://www.science.org/doi/abs/10.1126/science.adn0117},
eprint = {https://www.science.org/doi/pdf/10.1126/science.adn0117},}


@misc{zhou2024stealtheditshf,
      title={Stealth Edits: Detecting Stealth Edits in LLM Outputs}, 
      author={Qinghua Zhou},
      year={2024},
      howpublished={Hugging Face Spaces},
      url={https://huggingface.co/spaces/qinghua-zhou/stealth-edits},
}

@article{siam2024exploitllms,
      title={How to Exploit Large Language Models for Good or Bad}, 
      author={Alec Edgington},
      year={2024},
      journal={SIAM News},
      volume={57},
      number={1},
      url={https://www.siam.org/publications/siam-news/articles/how-to-exploit-large-language-models-for-good-or-bad/},
}


@misc{sutton2024stealtheditslargelanguage,
      title={Stealth edits to large language models}, 
      author={Oliver J. Sutton and Qinghua Zhou and Wei Wang and Desmond J. Higham and Alexander N. Gorban and Alexander Bastounis and Ivan Y. Tyukin},
      year={2024},
      eprint={2406.12670},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.12670}, 
}

@misc{exabeam2024airegulations,
      title={AI Regulations and LLM Regulations: Past, Present, and Future}, 
      author={Exabeam},
      year={2024},
      howpublished={Exabeam Blog},
      url={https://www.exabeam.com/explainers/ai-cyber-security/ai-regulations-and-llm-regulations-past-present-and-future/},
}


@techreport{ema2024llmguidelines,
      title={Guiding principles for the use of large language models in regulatory science and medicines regulatory activities}, 
      author={{European Medicines Agency}},
      year={2024},
      institution={European Medicines Agency},
      type={Guidance Document},
      url={https://www.ema.europa.eu/en/documents/other/guiding-principles-use-large-language-models-regulatory-science-medicines-regulatory-activities_en.pdf},
}




@misc{alaga2024gradingrubricaisafety,
      title={A Grading Rubric for AI Safety Frameworks}, 
      author={Jide Alaga and Jonas Schuett and Markus Anderljung},
      year={2024},
      eprint={2409.08751},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2409.08751}, 
}

@techreport{unicef2024aiguidance,
      title={Policy Guidance on AI for Children}, 
      author={{UNICEF}},
      year={2024},
      institution={UNICEF Office of Research - Innocenti},
      type={Policy Report},
      url={https://www.unicef.org/innocenti/reports/policy-guidance-ai-children},
}










@article{doi:10.1098/rsos.240197,
author = {Wachter, Sandra  and Mittelstadt, Brent  and Russell, Chris },
title = {Do large language models have a legal duty to tell the truth?},
journal = {Royal Society Open Science},
volume = {11},
number = {8},
pages = {240197},
year = {2024},
doi = {10.1098/rsos.240197},

URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rsos.240197},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.240197}
}

@misc{china2023generativeai,
      title={China: Generative AI Measures Finalized},
      author={{Library of Congress}},
      year={2023},
      institution={Law Library of Congress},
      type={Global Legal Monitor},
      month={July},
      url={https://www.loc.gov/item/global-legal-monitor/2023-07-18/china-generative-ai-measures-finalized/},
}

@techreport{nist2024riskframework,
      title={AI Risk Management Framework}, 
      author={{National Institute of Standards and Technology}},
      year={2024},
      institution={National Institute of Standards and Technology},
      type={Technical Report},
      url={https://www.nist.gov/itl/ai-risk-management-framework},
}


@techreport{openai2024preparedness,
      title={OpenAI Preparedness Framework}, 
      author={{OpenAI}},
      year={2024},
      institution={OpenAI},
      type={Technical Report},
      url={https://cdn.openai.com/openai-preparedness-framework-beta.pdf},
}

@techreport{anthropic2024scaling,
      title={Anthropic's Responsible Scaling Policy}, 
      author={{Anthropic}},
      year={2024},
      institution={Anthropic},
      type={Technical Report},
      url={https://www-cdn.anthropic.com/1adf000c8f675958c2ee23805d91aaade1cd4613/responsible-scaling-policy.pdf},
}

@techreport{deepmind2024frontier,
      title={The Frontier Safety Framework}, 
      author={{DeepMind}},
      year={2024},
      institution={DeepMind},
      type={Technical Report},
      url={https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/introducing-the-frontier-safety-framework/fsf-technical-report.pdf},
}

@misc{perez2022redteaminglanguagemodels,
      title={Red Teaming Language Models with Language Models}, 
      author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nat McAleese and Geoffrey Irving},
      year={2022},
      eprint={2202.03286},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.03286}, 
}

@misc{cambria2024xaimeetsllmssurvey,
      title={XAI meets LLMs: A Survey of the Relation between Explainable AI and Large Language Models}, 
      author={Erik Cambria and Lorenzo Malandri and Fabio Mercorio and Navid Nobani and Andrea Seveso},
      year={2024},
      eprint={2407.15248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.15248}, 
}

@misc{askell2023constitutionalai,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Amanda Askell and Yuntao Bai and Anna Chen and Deep Ganguli and Danny Hernandez and Jared Kaplan and Jackson Kernion and Ben Mann and Catherine Olsson and Paul Christiano},
      year={2023},
      institution={Anthropic},
      url={https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback},
}

@misc{li2024saladbenchhierarchicalcomprehensivesafety,
      title={SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models}, 
      author={Lijun Li and Bowen Dong and Ruohui Wang and Xuhao Hu and Wangmeng Zuo and Dahua Lin and Yu Qiao and Jing Shao},
      year={2024},
      eprint={2402.05044},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.05044}, 
}

@misc{opensafetylab2024saladdata,
      title={Salad-Data: A Hierarchical and Comprehensive Safety Dataset for Large Language Models},
      author={{OpenSafetyLab}},
      year={2024},
      howpublished={Hugging Face Dataset},
      url={https://huggingface.co/datasets/OpenSafetyLab/Salad-Data},
}

@misc{opensafetylab2024saladbenchleaderboard,
      title={Salad-Bench Leaderboard},
      author={{OpenSafetyLab}},
      year={2024},
      howpublished={Hugging Face Space},
      url={https://huggingface.co/spaces/OpenSafetyLab/Salad-Bench-Leaderboard},
}

@misc{gptfuzzer2024,
      title={GPTFuzzer: Red Teaming Large Language Models with Auto-Generated Safety Test Cases}, 
      author={Jiahao Yu and Xingwei Lin and Xinyu Xing},
      year={2024},
      howpublished={Papers with Code},
      url={https://paperswithcode.com/dataset/gptfuzzer},
}

@book{derman2011models,
  title={Models.Behaving.Badly.: Why Confusing Illusion with Reality Can Lead to Disaster, on Wall Street and in Life},
  author={Derman, E.},
  isbn={9781439165010},
  lccn={2011015006},
  url={https://books.google.co.uk/books?id=lke_cwM4wm8C},
  year={2011},
  publisher={Free Press}
}


@misc{safebench2024,
      title={SafeBench: A Comprehensive Benchmark for LLM Safety Evaluation},
      author={{ML Safety Team}},
      year={2024},
      howpublished={ML Safety Website},
      url={https://www.mlsafety.org/safebench},
}


@misc{mazeika2024harmbenchstandardizedevaluationframework,
      title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal}, 
      author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
      year={2024},
      eprint={2402.04249},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.04249}, 
}

@misc{harmbench2024,
    title={HarmBench},
    author={{Center for AI Safety}},
    year={2024},
    howpublished={GitHub repository},
    url={https://github.com/centerforaisafety/HarmBench},
    note={Framework for evaluating language model safety}
}

@misc{harmbenchresults2024,
    title={HarmBench Leaderboard},
    author={{Center for AI Safety}},
    year={2024},
    url={https://www.harmbench.org/results},
    note={Leaderboard tracking performance of language models on safety benchmarks}
}


@misc{guha2023legalbench,
      title={LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models}, 
      author={Neel Guha and Julian Nyarko and Daniel E. Ho and Christopher Ré and Adam Chilton and Aditya Narayana and Alex Chohlas-Wood and Austin Peters and Brandon Waldon and Daniel N. Rockmore and Diego Zambrano and Dmitry Talisman and Enam Hoque and Faiz Surani and Frank Fagan and Galit Sarfaty and Gregory M. Dickinson and Haggai Porat and Jason Hegland and Jessica Wu and Joe Nudell and Joel Niklaus and John Nay and Jonathan H. Choi and Kevin Tobia and Margaret Hagan and Megan Ma and Michael Livermore and Nikon Rasumov-Rahe and Nils Holzenberger and Noam Kolt and Peter Henderson and Sean Rehaag and Sharad Goel and Shang Gao and Spencer Williams and Sunny Gandhi and Tom Zur and Varun Iyer and Zehua Li},
      year={2023},
      eprint={2308.11462},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.11462}, 
}

@misc{surgeaiprofanity2024,
    title={Surge AI Profanity Dataset},
    author={{Surge AI}},
    year={2024},
    howpublished={GitHub repository},
    url={https://github.com/surge-ai/profanity},
    note={A comprehensive dataset for training and evaluating profanity detection models}
}


@misc{
zhang2024finbench,
title={FinBench: Benchmarking {LLM}s in Complex Financial Problem Solving and Reasoning},
author={Zhihan Zhang and Yixin Cao and Lizi Liao},
year={2024},
url={https://openreview.net/forum?id=AeGrf1uY0p}
}

@article{patil2023gorilla,
  title={Gorilla: Large Language Model Connected with Massive APIs},
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  year={2023},
  journal={arXiv preprint arXiv:2305.15334},
} 

@misc{mistralmoderation2024,
    title={Mistral Moderation: A Technical Report},
    author={{Mistral AI}},
    year={2024},
    url={https://mistral.ai/news/mistral-moderation/}
}

@misc{openaimoderation2024,
    title={OpenAI Moderation API},
    author={{OpenAI}},
    year={2024},
    url={https://platform.openai.com/docs/guides/moderation},
    note={Documentation for OpenAI's content moderation API}
}

@misc{llmguard2024,
    title={LLM-Guard: Comprehensive Safety and Security Framework for Large Language Models},
    author={{ProtectAI}},
    year={2024},
    url={https://github.com/protectai/llm-guard},
    note={An open-source toolkit for LLM security and safety}
}

@misc{nemogr2024,
    title={NeMo-Guardrails: An Open-Source Toolkit for Building Reliable and Safe LLM Applications},
    author={{NVIDIA}},
    year={2024},
    url={https://github.com/NVIDIA/NeMo-Guardrails},
    note={A framework for creating reliable and safe LLM applications with customizable guardrails}
}

@misc{awscomprehend2024,
    title={Amazon Comprehend - Natural Language Processing Service},
    author={{Amazon Web Services}},
    year={2024},
    url={https://aws.amazon.com/comprehend/},
    note={AWS natural language processing service for text analysis and content moderation}
}


@misc{ibmriskatlas2024,
    title={IBM watsonx.ai Risk Atlas},
    author={{IBM}},
    year={2024},
    url={https://www.ibm.com/docs/en/watsonx/saas?topic=ai-risk-atlas},
    note={A framework for identifying and mitigating risks in AI systems}
}


@misc{padhi2024graniteguardian,
      title={Granite Guardian}, 
      author={Inkit Padhi and Manish Nagireddy and Giandomenico Cornacchia and Subhajit Chaudhury and Tejaswini Pedapati and Pierre Dognin and Keerthiram Murugesan and Erik Miehling and Martín Santillán Cooper and Kieran Fraser and Giulio Zizzo and Muhammad Zaid Hameed and Mark Purcell and Michael Desmond and Qian Pan and Inge Vejsbjerg and Elizabeth M. Daly and Michael Hind and Werner Geyer and Ambrish Rawat and Kush R. Varshney and Prasanna Sattigeri},
      year={2024},
      eprint={2412.07724},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.07724}, 
}

@misc{mistral2024,
    title={System-Level Guardrails for Mistral},
    author={{Mistral}},
    year={2024},
    url={https://github.com/mistralai/cookbook/blob/main/mistral/moderation/system-level-guardrails.ipynb},
    note={A Jupyter notebook detailing system-level guardrails for Mistral models}
}


